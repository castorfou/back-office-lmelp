"""Service autonome pour la consultation des statistiques du cache livres/auteurs."""

from typing import Any

from .livres_auteurs_cache_service import livres_auteurs_cache_service
from .mongodb_service import mongodb_service


class StatsService:
    """Service pour consulter les statistiques du syst√®me cache-first."""

    def __init__(self):
        """Initialise le service de statistiques."""
        self.cache_service = livres_auteurs_cache_service
        self.mongodb_service = mongodb_service

    def get_cache_statistics(self) -> dict[str, Any]:
        """
        R√©cup√®re les statistiques optimis√©es depuis le cache.

        Returns:
            Dictionnaire avec les statistiques compl√®tes (incluant m√©triques Issue #124 et #128)
        """
        result = self.cache_service.get_statistics_from_cache()
        stats = dict(result) if result else {}

        # Issue #124: Ajouter m√©triques de compl√©tude URL Babelio
        stats["books_without_url_babelio"] = self._count_books_without_url_babelio()
        stats["authors_without_url_babelio"] = self._count_authors_without_url_babelio()

        # Issue #128: Ajouter nouvelles m√©triques
        stats["last_episode_date"] = self._get_last_episode_date()
        stats["episodes_without_avis_critiques"] = (
            self._count_episodes_without_avis_critiques()
        )
        stats["avis_critiques_without_analysis"] = (
            self._count_avis_critiques_without_analysis()
        )

        # Issue #185: Ajouter m√©triques des badges d'√©missions
        stats["emissions_sans_avis"] = self._count_emissions_sans_avis()
        stats["emissions_with_problems"] = self._count_emissions_with_problems()

        return stats

    def _count_books_without_url_babelio(self) -> int:
        """
        Compte les livres sans URL Babelio (Issue #124, #128).

        Compte uniquement les livres √† traiter manuellement (sans url_babelio).
        Exclut les livres avec babelio_not_found: true car confirm√©s comme absents de Babelio.

        Returns:
            Nombre de livres sans lien Babelio (√† traiter manuellement)
        """
        livres_collection = self.mongodb_service.get_collection("livres")
        count: int = livres_collection.count_documents(
            {
                "$and": [
                    {
                        "$or": [
                            {"url_babelio": None},
                            {"url_babelio": {"$exists": False}},
                        ]
                    },
                    {
                        "$or": [
                            {"babelio_not_found": {"$ne": True}},
                            {"babelio_not_found": {"$exists": False}},
                        ]
                    },
                ]
            }
        )
        return count

    def _count_authors_without_url_babelio(self) -> int:
        """
        Compte les auteurs sans URL Babelio (Issue #124, #128).

        Compte uniquement les auteurs √† traiter manuellement (sans url_babelio).
        Exclut les auteurs avec babelio_not_found: true car confirm√©s comme absents de Babelio.

        Returns:
            Nombre d'auteurs sans lien Babelio (√† traiter manuellement)
        """
        auteurs_collection = self.mongodb_service.get_collection("auteurs")
        count: int = auteurs_collection.count_documents(
            {
                "$and": [
                    {
                        "$or": [
                            {"url_babelio": None},
                            {"url_babelio": {"$exists": False}},
                        ]
                    },
                    {
                        "$or": [
                            {"babelio_not_found": {"$ne": True}},
                            {"babelio_not_found": {"$exists": False}},
                        ]
                    },
                ]
            }
        )
        return count

    def _get_last_episode_date(self) -> str | None:
        """
        R√©cup√®re la date du dernier √©pisode en base (Issue #128).

        Returns:
            Date de diffusion du dernier √©pisode (format ISO), ou None si aucun √©pisode
        """
        episodes_collection = self.mongodb_service.get_collection("episodes")
        last_episode = episodes_collection.find_one(
            sort=[("diffusion", -1)], projection={"diffusion": 1}
        )
        if last_episode and "diffusion" in last_episode:
            # Retourner la date au format ISO string
            diffusion = last_episode["diffusion"]
            if hasattr(diffusion, "isoformat"):
                return str(diffusion.isoformat())
            return str(diffusion)
        return None

    def _count_episodes_without_avis_critiques(self) -> int:
        """
        Compte les √©pisodes non masqu√©s sans avis critiques extraits (Issue #128).

        Returns:
            Nombre d'√©pisodes o√π masked=False et n'ont pas d'avis critiques
        """
        episodes_collection = self.mongodb_service.get_collection("episodes")
        avis_critiques_collection = self.mongodb_service.get_collection(
            "avis_critiques"
        )

        # Compter les √©pisodes non masqu√©s
        non_masked_count = episodes_collection.count_documents(
            {"$or": [{"masked": False}, {"masked": {"$exists": False}}]}
        )

        # FIX: Utiliser aggregation pour filtrer les avis dont l'√©pisode est masqu√©
        # Seuls les avis_critiques avec √©pisode non masqu√© doivent √™tre compt√©s
        pipeline = [
            {
                "$lookup": {
                    "from": "episodes",
                    "let": {"episode_oid_str": "$episode_oid"},
                    "pipeline": [
                        {
                            "$match": {
                                "$expr": {
                                    "$eq": [{"$toString": "$_id"}, "$$episode_oid_str"]
                                }
                            }
                        }
                    ],
                    "as": "episode",
                }
            },
            {"$unwind": "$episode"},
            {
                "$match": {
                    "$or": [
                        {"episode.masked": {"$ne": True}},
                        {"episode.masked": {"$exists": False}},
                    ]
                }
            },
            {"$group": {"_id": "$episode_oid"}},
        ]

        episodes_with_avis_non_masques = list(
            avis_critiques_collection.aggregate(pipeline)
        )
        episodes_with_avis_count = len(episodes_with_avis_non_masques)

        # Retourner la diff√©rence
        return int(max(0, non_masked_count - episodes_with_avis_count))

    def _count_avis_critiques_without_analysis(self) -> int:
        """
        Compte les √©pisodes non masqu√©s avec avis critiques mais sans analyse (Issue #128, #143, #148).

        Un √©pisode est consid√©r√© comme "avec avis critique" s'il existe au moins un document
        dans avis_critiques qui r√©f√©rence cet √©pisode.

        Un √©pisode est consid√©r√© comme "analys√©" s'il existe au moins un document
        dans livresauteurs_cache qui r√©f√©rence cet √©pisode.

        Exclut les √©pisodes masqu√©s (Issue #143).

        Returns:
            Nombre d'√©pisodes avec avis critiques mais sans analyse (√©pisodes non masqu√©s uniquement)
        """
        episodes_collection = self.mongodb_service.get_collection("episodes")
        avis_critiques_collection = self.mongodb_service.get_collection(
            "avis_critiques"
        )
        cache_collection = self.mongodb_service.get_collection("livresauteurs_cache")

        # R√©cup√©rer les IDs des √©pisodes NON masqu√©s
        non_masked_episodes = episodes_collection.find(
            {"$or": [{"masked": False}, {"masked": {"$exists": False}}]}, {"_id": 1}
        )
        non_masked_episode_ids = {ep["_id"] for ep in non_masked_episodes}

        # R√©cup√©rer les √©pisodes distincts qui ont des avis critiques
        # IMPORTANT (Issue #148): episode_oid est stock√© comme STRING dans la base,
        # on doit le convertir en ObjectId pour matcher avec les IDs de episodes.find()
        from bson import ObjectId

        episodes_with_avis = {
            ObjectId(ep_id) if isinstance(ep_id, str) else ep_id
            for ep_id in avis_critiques_collection.distinct("episode_oid")
            if ep_id is not None
        }

        # Filtrer pour ne garder que les √©pisodes NON masqu√©s
        episodes_with_avis_non_masked = episodes_with_avis & non_masked_episode_ids

        # R√©cup√©rer les √©pisodes distincts qui ont √©t√© analys√©s
        # IMPORTANT (Issue #148): episode_oid est stock√© comme STRING dans la base,
        # on doit le convertir en ObjectId pour matcher avec les IDs de episodes.find()
        episodes_analyzed = {
            ObjectId(ep_id) if isinstance(ep_id, str) else ep_id
            for ep_id in cache_collection.distinct("episode_oid")
            if ep_id is not None
        }

        # Filtrer pour ne garder que les √©pisodes NON masqu√©s
        episodes_analyzed_non_masked = episodes_analyzed & non_masked_episode_ids

        # Calculer la diff√©rence: √©pisodes avec avis mais non analys√©s
        count_with_avis = len(episodes_with_avis_non_masked)
        count_analyzed = len(episodes_analyzed_non_masked)

        return int(max(0, count_with_avis - count_analyzed))

    def get_detailed_breakdown(self) -> list[dict[str, Any]]:
        """
        R√©cup√®re une r√©partition d√©taill√©e par biblio_verification_status.

        Returns:
            Liste des groupes avec comptes et exemples de livres
        """
        cache_collection = self.mongodb_service.get_collection("livresauteurs_cache")

        pipeline = [
            {
                "$group": {
                    "_id": "$biblio_verification_status",
                    "count": {"$sum": 1},
                    "books": {"$push": {"auteur": "$auteur", "titre": "$titre"}},
                }
            }
        ]

        return list(cache_collection.aggregate(pipeline))

    def get_validation_status_breakdown(self) -> list[dict[str, Any]]:
        """
        R√©cup√®re la r√©partition par validation_status.

        Returns:
            Liste des statuts de validation avec comptes
        """
        cache_collection = self.mongodb_service.get_collection("livresauteurs_cache")

        pipeline = [{"$group": {"_id": "$validation_status", "count": {"$sum": 1}}}]

        return list(cache_collection.aggregate(pipeline))

    def get_recent_processed_books(self, limit: int = 5) -> list[dict[str, Any]]:
        """
        R√©cup√®re les livres r√©cemment auto-trait√©s.

        Args:
            limit: Nombre maximum de livres √† retourner

        Returns:
            Liste des livres r√©cemment trait√©s
        """
        cache_collection = self.mongodb_service.get_collection("livresauteurs_cache")

        return list(
            cache_collection.find({"validation_status": "mongo"})
            .sort("processed_at", -1)
            .limit(limit)
        )

    def get_human_readable_summary(self) -> str:
        """
        Formate un r√©sum√© lisible des statistiques.

        Returns:
            R√©sum√© format√© pour affichage console
        """
        stats = self.get_cache_statistics()

        total_en_attente = (
            stats.get("couples_suggested_pas_en_base", 0)
            + stats.get("couples_not_found_pas_en_base", 0)
            + stats.get("couples_pending", 0)
        )

        total_traites = (
            stats.get("couples_en_base", 0)
            + total_en_attente
            + stats.get("couples_rejected", 0)
        )

        summary = f"""üìä STATISTIQUES CACHE LIVRES/AUTEURS

üöÄ Auto-trait√©s (en base) : {stats.get("couples_en_base", 0)} (couples)
üìö Livres uniques         : {stats.get("livres_uniques", 0)}
‚è≥ En attente validation  : {total_en_attente}
   ‚îú‚îÄ üí° Suggestions      : {stats.get("couples_suggested_pas_en_base", 0)}
   ‚îú‚îÄ ‚ùå Non trouv√©s      : {stats.get("couples_not_found_pas_en_base", 0)}
   ‚îî‚îÄ ‚è∏Ô∏è  Pending         : {stats.get("couples_pending", 0)}
üóëÔ∏è  Rejet√©s             : {stats.get("couples_rejected", 0)}
üì∫ Avis critiques analys√©s : {stats.get("avis_critiques_analyses", 0)}
üìù √âpisodes non trait√©s : {stats.get("episodes_non_traites", 0)}

Total livres trait√©s : {total_traites}"""

        return summary

    def display_console_stats(self) -> None:
        """Affiche les statistiques compl√®tes dans la console."""
        print(self.get_human_readable_summary())
        print()

        # Afficher la r√©partition d√©taill√©e
        print("üîç R√âPARTITION D√âTAILL√âE PAR STATUT:")
        breakdown = self.get_detailed_breakdown()

        for group in breakdown:
            status = group["_id"] or "null"
            count = group["count"]
            books = group.get("books", [])

            status_emoji = {
                "verified": "‚úÖ",
                "suggested": "üí°",
                "not_found": "‚ùå",
                "pending": "‚è∏Ô∏è",
                "null": "‚ùì",
            }.get(status, "üìÑ")

            print(f"  {status_emoji} {status}: {count} livre(s)")

            # Afficher quelques exemples
            for book in books[:3]:  # Max 3 exemples
                print(f"    - {book['auteur']} - {book['titre']}")

            if len(books) > 3:
                print(f"    ... et {len(books) - 3} autres")
            print()

        # Afficher les livres r√©cemment trait√©s
        print("üïí R√âCEMMENT AUTO-TRAIT√âS:")
        recent = self.get_recent_processed_books()

        if recent:
            for book in recent:
                processed_date = book.get("processed_at", "Date inconnue")
                print(f"  üìö {book['auteur']} - {book['titre']} ({processed_date})")
        else:
            print("  Aucun livre r√©cemment trait√©")

    def _count_emissions_sans_avis(self) -> int:
        """
        Compte les √©missions avec badge_status = "no_avis" (‚ö™).

        Ces √©missions n'ont pas encore d'avis extraits.

        IMPORTANT: badge_status n'est pas persist√© en MongoDB, il est calcul√©
        dynamiquement. Cette m√©thode it√®re sur toutes les √©missions et calcule
        le badge pour chacune.

        Returns:
            Nombre d'√©missions sans avis extraits
        """
        from back_office_lmelp.app import _calculate_emission_badge_status

        emissions_collection = self.mongodb_service.get_collection("emissions")
        emissions = list(
            emissions_collection.find(
                {}, {"_id": 1, "episode_id": 1, "avis_critique_id": 1}
            )
        )

        count = 0
        for emission in emissions:
            badge = _calculate_emission_badge_status(
                str(emission["_id"]), str(emission["episode_id"]), self.mongodb_service
            )
            if badge == "no_avis":
                count += 1

        return count

    def _count_emissions_with_problems(self) -> int:
        """
        Compte les √©missions avec probl√®mes = badge rouge (üî¥) + badge jaune (üü°).

        Rouge (count_mismatch): √âcart de comptage OU note manquante
        Jaune (unmatched): Livres non match√©s

        IMPORTANT: badge_status n'est pas persist√© en MongoDB, il est calcul√©
        dynamiquement. Cette m√©thode it√®re sur toutes les √©missions et calcule
        le badge pour chacune.

        Returns:
            Nombre total d'√©missions avec probl√®mes (rouge + jaune)
        """
        from back_office_lmelp.app import _calculate_emission_badge_status

        emissions_collection = self.mongodb_service.get_collection("emissions")
        emissions = list(
            emissions_collection.find(
                {}, {"_id": 1, "episode_id": 1, "avis_critique_id": 1}
            )
        )

        count = 0
        for emission in emissions:
            badge = _calculate_emission_badge_status(
                str(emission["_id"]), str(emission["episode_id"]), self.mongodb_service
            )
            if badge in ("count_mismatch", "unmatched"):
                count += 1

        return count


# Instance globale pour utilisation directe
stats_service = StatsService()

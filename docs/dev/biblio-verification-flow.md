# Service de V√©rification Bibliographique - Architecture et Flux de Traitement

## Vue d'ensemble

Le syst√®me de v√©rification bibliographique est un service multi-phase qui valide et corrige automatiquement les donn√©es bibliographiques (auteur, titre, √©diteur) extraites des avis critiques du Masque et la Plume.

**Contexte** : Les livres √† corriger proviennent de la collection MongoDB `avis_critique` (champ `summary`), g√©n√©r√©e depuis la transcription audio Whisper. Cette transcription automatique introduit des erreurs orthographiques que le service doit corriger.

Le service combine trois sources de donn√©es pour maximiser la fiabilit√© :

1. **Livres extraits directement** (Phase 0) - Livres identifi√©s dans les m√©tadonn√©es d'√©pisodes
2. **Ground truth fuzzy search** (Phase 1) - Recherche approximative dans les m√©tadonn√©es √©ditorialis√©es (titre + description) des √©pisodes
3. **Validation Babelio** (Phases 2-3) - V√©rification via l'API Babelio.com

## Architecture G√©n√©rale

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    BiblioValidationService                          ‚îÇ
‚îÇ                (Frontend - Orchestration)                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ             ‚îÇ             ‚îÇ
                ‚ñº             ‚ñº             ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Phase 0         ‚îÇ ‚îÇ Fuzzy Search ‚îÇ ‚îÇ Babelio Service  ‚îÇ
    ‚îÇ Babelio Direct  ‚îÇ ‚îÇ  (Phase 1)   ‚îÇ ‚îÇ  (Phases 2-3)    ‚îÇ
    ‚îÇ                 ‚îÇ ‚îÇ              ‚îÇ ‚îÇ                  ‚îÇ
    ‚îÇ Verify exact    ‚îÇ ‚îÇ Backend API  ‚îÇ ‚îÇ External API     ‚îÇ
    ‚îÇ author+title    ‚îÇ ‚îÇ /api/fuzzy-  ‚îÇ ‚îÇ /api/verify-     ‚îÇ
    ‚îÇ from avis_      ‚îÇ ‚îÇ search-      ‚îÇ ‚îÇ babelio          ‚îÇ
    ‚îÇ critique        ‚îÇ ‚îÇ episode      ‚îÇ ‚îÇ                  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   Arbitration    ‚îÇ
                    ‚îÇ   (Phase 4)      ‚îÇ
                    ‚îÇ                  ‚îÇ
                    ‚îÇ - Priority rules ‚îÇ
                    ‚îÇ - Confidence     ‚îÇ
                    ‚îÇ   scoring        ‚îÇ
                    ‚îÇ - Filtering      ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  Final Result    ‚îÇ
                    ‚îÇ                  ‚îÇ
                    ‚îÇ - verified       ‚îÇ
                    ‚îÇ - suggestion     ‚îÇ
                    ‚îÇ - not_found      ‚îÇ
                    ‚îÇ - error          ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Flux de Traitement D√©taill√©

### Phase 0 : Validation Directe Babelio (Nouveau - Issue #68)

**Objectif** : Pour chaque couple auteur-livre √† valider, effectuer une **v√©rification directe sur Babelio** avant toute autre tentative. C'est un test binaire simple : soit Babelio valide les donn√©es exactes, soit on passe √† la Phase 1.

**Processus** :
1. Recevoir les donn√©es √† valider : `author`, `title`, `episodeId`
2. Appeler **directement Babelio** : `verifyBook(title, author)`
3. **Si Babelio confirme** avec `status: 'verified'` ‚Üí ‚úÖ **Termin√©, retourner `verified`**
4. **Si Babelio ne confirme pas** (statut `not_found`, `corrected`, ou erreur) ‚Üí ‚ùå **Passer √† Phase 1** (fuzzy search)

**Fonctionnement de `verifyBook()` :**
- Recherche le livre sur Babelio avec fuzzy matching (tol√®re les fautes d'orthographe)
- Calcule un `confidence_score` (0.0 √† 1.0) bas√© sur la similarit√© des cha√Ænes (algorithme Ratcliff-Obershelp)
- Retourne un statut selon le seuil de confiance :
  - **`verified`** si `confidence_score >= 0.90` (correspondance quasi-exacte)
  - **`corrected`** si `confidence_score < 0.90` (suggestion de correction)
  - **`not_found`** si aucun livre trouv√© sur Babelio

**Conditions de succ√®s (Phase 0 accepte uniquement)** :
- Babelio retourne `status: 'verified'` ET `confidence_score >= 0.90`

**Conditions d'√©chec (passage Phase 1)** :
- Babelio retourne `not_found` (auteur/titre inconnu)
- Babelio retourne `corrected` avec `confidence_score < 0.90` (suggestion disponible mais pas assez fiable)
- Erreur r√©seau ou timeout

**Code source** :
- Frontend : `BiblioValidationService.js:79-122` (`_tryPhase0DirectValidation`)
- Backend API : `/api/verify-babelio` (endpoint Babelio)

**Exemple de succ√®s** :
```javascript
// Entr√©e (donn√©es extraites de avis_critique.summary via Whisper)
author: "Am√©lie Nothomb"
title: "Tant mieux"
episodeId: "68d98f74edbcf1765933a9b5"  // pragma: allowlist secret

// Phase 0 : V√©rification directe Babelio
verifyBook("Tant mieux", "Am√©lie Nothomb")
‚Üí status: 'verified', confidence: 1.0
‚Üí Babelio confirme : ces donn√©es sont exactes

// R√©sultat Phase 0 (termin√©)
{
  status: 'verified',
  data: {
    source: 'babelio_phase0',
    confidence_score: 1.0
  }
}
// ‚úÖ Pas besoin de fuzzy search, workflow termin√©
```

**Exemple d'√©chec (passage Phase 1) - Not Found** :
```javascript
// Entr√©e (faute d'orthographe dans la transcription Whisper)
author: "Alain Mabancou"  // Erreur : devrait √™tre "Mabanckou"
title: "Rams√®s de Paris"

// Phase 0 : V√©rification directe Babelio
verifyBook("Rams√®s de Paris", "Alain Mabancou")
‚Üí status: 'not_found'  // Babelio ne trouve pas "Mabancou"

// ‚ùå Phase 0 √©choue, passer √† Phase 1 (fuzzy search)
```

**Exemple d'√©chec (passage Phase 1) - Corrected** :
```javascript
// Entr√©e (faute l√©g√®re sur le titre dans la transcription Whisper)
author: "Am√©lie Nothomb"
title: "Tant mieu"  // Erreur : devrait √™tre "Tant mieux"

// Phase 0 : V√©rification directe Babelio
verifyBook("Tant mieu", "Am√©lie Nothomb")
‚Üí status: 'corrected'  // Babelio sugg√®re une correction
‚Üí babelio_suggestion_title: "Tant mieux"
‚Üí confidence_score: 0.85  // < 0.90 donc "corrected"

// ‚ùå Phase 0 √©choue car status != 'verified'
// Passer √† Phase 1 pour validation compl√®te avec fuzzy search
```

**Avantage** :
- √âvite le fuzzy search co√ªteux quand Whisper a correctement transcrit les donn√©es
- R√©duit la latence (1 seul appel Babelio au lieu de 3 minimum)
- Simple et rapide : test binaire sans arbitrage complexe

---

### Phase 1 : Ground Truth Fuzzy Search

**Objectif** : Rechercher les donn√©es bibliographiques dans les **m√©tadonn√©es √©ditorialis√©es** de l'√©pisode (champs `titre` + `description` v√©rifi√©s par l'√©diteur France Inter).

**Important** : Cette recherche ne se fait **pas** sur la transcription audio brute, mais sur les m√©tadonn√©es MongoDB de la collection `episodes` qui sont des donn√©es fiables et √©ditorialis√©es.

**Exemple de document `episodes` MongoDB** :
```json
{
  "_id": "68d98f74edbcf1765933a9b5",
  "titre": "Catherine Millet, Sorj Chalandon, Rebeka Warrior, Am√©lie Nothomb...",
  "description": "Le nouveau texte de Sigrid Nunez ou encore celui d'Am√©lie Nothomb sur sa m√®re...",
  "type": "livres",
  "date": "2025-09-28T10:59:39.000Z"
}
```

**Processus** :
1. Appel API : `POST /api/fuzzy-search-episode`
   ```javascript
   {
     episode_id: "68bd9ed3582cf994fb66f1d6",  // pragma: allowlist secret
     query_title: "Fleurs intestinales",
     query_author: "Vamille"
   }
   ```

2. Backend extrait les m√©tadonn√©es de l'√©pisode :
   - R√©cup√©ration depuis MongoDB (`episodes` collection)
   - Combinaison des champs `titre` + `description` (donn√©es √©ditorialis√©es)
   - Extraction des segments entre guillemets (priorit√© haute pour titres)
   - Extraction des mots > 3 caract√®res

3. Recherche fuzzy avec `rapidfuzz` (Python) :
   - **Titres** : Recherche dans segments entre guillemets (marqueur üìñ) + mots g√©n√©raux
   - **Auteurs** : Recherche dans tous les candidats textuels
   - Scores de similarit√© calcul√©s (0-100)

4. R√©ponse API :
   ```javascript
   {
     found_suggestions: true,
     title_matches: [
       ["üìñ Fleurs intestinales", 100],
       ["intestinales", 75]
     ],
     author_matches: [
       ["Vamille", 98]
     ]
   }
   ```

**Seuils de qualit√©** :
- **Good matches** : `titleScore >= 80 && authorScore >= 80`
- **Decent matches** : `titleScore >= 75 && authorScore >= 75` (assoupli pour variantes)
- **Perfect author boost** : Si `authorScore >= 85`, seuil titre r√©duit √† 35

**Code source** :
- Backend : `app.py:583-674` (endpoint `/api/fuzzy-search-episode`)
- Frontend : `BiblioValidationService.js:426-518` (`_hasGoodGroundTruthMatches`, `_hasDecentGroundTruthMatches`)

**Limites connues** (voir Issue #74) :
- Peut retourner des **URLs** : `https://www.franceinter.fr/...` (pr√©sentes dans le champ `description`)
- Peut retourner des **fragments trop courts** : `am`, `de`, `Am√©lie`
- N√©cessite filtrage avant utilisation (voir Phase 4)

**Note** : Le fuzzy search √©choue parfois car les m√©tadonn√©es `titre` et `description` ne contiennent pas toujours les noms complets ou corrects des auteurs/titres (contrairement aux donn√©es Babelio qui sont normalis√©es).

**Origine des donn√©es √† corriger** :
Les livres/auteurs √† valider proviennent de la collection `avis_critique` (champ `summary`), qui est g√©n√©r√©e depuis la **transcription audio Whisper**. C'est cette transcription automatique qui introduit les erreurs orthographiques (ex: "Alain Mabancou" au lieu de "Mabanckou").

---

### Phase 2 : Validation Babelio de l'Auteur

**Objectif** : V√©rifier et corriger l'orthographe de l'auteur via l'API AJAX de Babelio.

**Processus** :
1. Appel API : `POST /api/verify-babelio`
   ```javascript
   {
     type: "author",
     name: "Alain Mabancou"  // Faute d'orthographe
   }
   ```

2. Backend interroge Babelio :
   - Endpoint : `https://www.babelio.com/aj_recherche.php`
   - Rate limiting : 0.8 sec entre requ√™tes
   - Cache disque + m√©moire pour performances
   - Headers/cookies appropri√©s pour √©viter blocages

3. R√©ponse Babelio (via BabelioService) :
   ```javascript
   {
     status: "corrected",  // ou "verified" si exact
     original: "Alain Mabancou",
     babelio_suggestion: "Alain Mabanckou",
     confidence_score: 0.95,
     babelio_data: {
       id: "2180",
       prenoms: "Alain",
       nom: "Mabanckou",
       type: "auteurs",
       ca_membres: "30453"
     },
     babelio_url: "https://www.babelio.com/auteur/Alain-Mabanckou/2180"
   }
   ```

**Statuts possibles** :
- `verified` : Orthographe exacte confirm√©e (`confidence_score >= 0.95`)
- `corrected` : Suggestion de correction (`confidence_score < 0.95`)
- `not_found` : Aucun auteur trouv√©
- `error` : Erreur technique (timeout, r√©seau, etc.)

**Code source** :
- Backend : `babelio_service.py:317-379` (`verify_author`)
- Scoring : `babelio_service.py:570-586` (`_calculate_similarity` - algorithme Ratcliff-Obershelp)

---

### Phase 3 : Validation Babelio du Livre

**Objectif** : V√©rifier et corriger le titre du livre, en tenant compte de la suggestion d'auteur.

**Processus** :
1. **Strat√©gie intelligente** (BiblioValidationService) :
   - Si Phase 2 sugg√®re une correction d'auteur :
     - Essayer d'abord avec l'auteur **original**
     - Si √©chec (`not_found`), r√©essayer avec l'auteur **sugg√©r√©**
   - Sinon, tester uniquement avec l'auteur original

2. Appel API : `POST /api/verify-babelio`
   ```javascript
   {
     type: "book",
     title: "Rams√®s de Paris",
     author: "Alain Mabanckou"  // Auteur corrig√© de Phase 2
   }
   ```

3. R√©ponse Babelio :
   ```javascript
   {
     status: "verified",
     original_title: "Rams√®s de Paris",
     babelio_suggestion_title: "Rams√®s de Paris",
     original_author: "Alain Mabanckou",
     babelio_suggestion_author: "Alain Mabanckou",
     confidence_score: 1.0,
     babelio_data: {
       id_oeuvre: "1770",
       titre: "Rams√®s de Paris",
       prenoms: "Alain",
       nom: "Mabanckou",
       type: "livres"
     }
   }
   ```

**Cascade de recherche** (exemple complexe - Caroline Dussain) :
```
1. verifyAuthor("Caroline Dussain")
   ‚Üí sugg√®re "Caroline Dawson" (confidence: 0.82)

2. verifyBook("Un d√©ni fran√ßais", "Caroline Dussain")
   ‚Üí not_found

3. verifyBook("Un d√©ni fran√ßais", "Caroline Dawson")
   ‚Üí sugg√®re "Caroline du Saint - Un D√©ni fran√ßais - Enqu√™te sur l'√©levage industrie..."
   ‚Üí (confidence: 0.88)

R√©sultat final: Caroline du Saint - Un D√©ni fran√ßais - Enqu√™te...
```

**Code source** :
- Backend : `babelio_service.py:380-461` (`verify_book`)
- Frontend : `BiblioValidationService.js:188-242` (logique de cascade)
- Scoring : Combin√© (70% titre + 30% auteur) pour livres

---

### Phase 4 : Arbitrage et D√©cision Finale

**Objectif** : Combiner les r√©sultats des 3 sources avec r√®gles de priorit√© et filtrage intelligent.

#### 4.1 Filtrage des Suggestions Invalides (Issue #74)

**Avant l'arbitrage**, filtrer les suggestions ground truth invalides via `_isValidTitleSuggestion()` :

**R√®gles de rejet** :
- URLs compl√®tes : `http://`, `https://`, `www.`, `franceinter.fr`, `.com`, `.fr`
- Fragments trop courts : `< 3 caract√®res` (sauf si exact match avec original)
- Mots isol√©s courts : `< 8 caract√®res` pour un seul mot (filtre "Am√©lie", "tous", etc.)

**Exemple de filtrage** :
```javascript
// Entr√©e fuzzy search
titleMatches: [
  ["üìñ https://www.franceinter.fr/emissions/le-masque", 36],  // ‚ùå URL
  ["üìñ Am√©lie", 64],                                          // ‚ùå Pr√©nom seul
  ["üìñ Tant mieux", 92]                                       // ‚úÖ Valide
]

// Apr√®s filtrage
titleMatches: [
  ["üìñ Tant mieux", 92]  // Seule suggestion gard√©e
]
```

**Code source** : `BiblioValidationService.js:697-728` (`_isValidTitleSuggestion`)

#### 4.2 Ordre de Priorit√© des Sources

**R√®gle 1 : Ground Truth avec Good Matches** (priorit√© absolue)
- **Conditions** : `titleScore >= 80 && authorScore >= 80` + suggestion valide
- **Action** : Utiliser la suggestion ground truth
- **Validation** : V√©rifier coh√©rence avec Babelio si possible
- **Exemple** : Vamille - Fleurs intestinales (scores 100/98)

**R√®gle 2 : Ground Truth avec Decent Matches** (priorit√© forte)
- **Conditions** : `titleScore >= 75 && authorScore >= 75` + suggestion valide
- **Cas sp√©cial** : Si `authorScore >= 85`, accepter `titleScore >= 35`
- **Action** : Utiliser ground truth **sans exiger confirmation Babelio**
- **Exemple** : Emmanuel Carr√®re - Colcause ‚Üí Kolkhoze (scores 85/35)

**R√®gle 3 : Validation Directe Babelio** (pas de suggestion)
- **Conditions** :
  - `authorValidation.status === 'verified'` ET pas de suggestion d'auteur
  - `bookValidation.status === 'verified'`
  - Pas de ground truth utilisable
- **Action** : Retourner `status: 'verified'` (donn√©es originales exactes)
- **Exemple** : Alice Ferney - Comme en amour

**R√®gle 4 : Suggestion Babelio Seule**
- **Conditions** : Babelio propose une correction (`status: 'corrected'` ou `'verified'` avec diff√©rence)
- **Filtrage** : Rejeter si `confidence_score < 0.8` (sauf si livre valid√© + auteur connu)
- **Action** : Retourner `status: 'suggestion'` avec donn√©es Babelio
- **Exemple** : Alain Mabancou ‚Üí Alain Mabanckou

**R√®gle 5 : Not Found** (aucune source fiable)
- **Conditions** : Aucune des r√®gles ci-dessus ne s'applique
- **Action** : Retourner `status: 'not_found'`
- **Exemples** : Gr√©gory Lefloc - Peau d'ours (n√©cessite intervention manuelle)

**Code source** : `BiblioValidationService.js:293-420` (`_arbitrateResults`)

#### 4.3 Reconstruction du Nom d'Auteur (Ground Truth)

Lorsque ground truth retourne des **fragments d'auteur** (ex: `["Alikavazovic", 82], ["Jakuta", 78]`), le service reconstruit le nom complet :

**Algorithme de reconstruction** :
1. Filtrer les mots parasites : `pour`, `de`, `du`, `la`, `le`, `et`, `dans`, etc.
2. Nettoyer les fragments : enlever `d'`, `l'`, `de ` du d√©but
3. Identifier pr√©nom vs nom :
   - Heuristique longueur (pr√©nom g√©n√©ralement plus court)
   - D√©tection pattern majuscule + minuscules
   - Unicode-aware pour noms accentu√©s
4. Ordre final : `Pr√©nom Nom`

**Exemple** :
```javascript
// Entr√©e fuzzy
authorMatches: [
  ["Alikavazovic", 82],
  ["Jakuta", 78],
  ["pour", 65]  // Bruit
]

// Apr√®s reconstruction
reconstructedAuthor: "Jakuta Alikavazovic"
// Jakuta (plus court, pattern pr√©nom) + Alikavazovic (nom)
```

**Code source** : `BiblioValidationService.js:524-690` (`_extractGroundTruthSuggestion`)

#### 4.4 Priorisation des Titres (Ground Truth)

Lorsque fuzzy search retourne **plusieurs titres candidats**, le service utilise un score combin√© :

**Algorithme de scoring** :
1. Calculer **similarit√© Levenshtein** entre titre original et candidat (normalis√© 0-1)
2. Normaliser **score fuzzy** de rapidfuzz (0-1)
3. Score combin√© : `similarit√© √ó 0.7 + score_fuzzy √ó 0.3`
4. Filtrer les suggestions invalides (URLs, fragments)
5. Trier par score combin√© d√©croissant
6. Retourner le meilleur match

**Exemple** :
```javascript
// Entr√©e
original.title: "Colcause"

titleMatches: [
  ["üìñ Kolkhoze", 75],      // Similarit√©: 0.85 ‚Üí combin√©: 0.82
  ["üìñ Kolkhoz", 78],       // Similarit√©: 0.80 ‚Üí combin√©: 0.79
  ["cause", 90]             // Similarit√©: 0.50 ‚Üí combin√©: 0.62
]

// R√©sultat : "Kolkhoze" (meilleur compromis similarit√©/score)
```

**Code source** : `BiblioValidationService.js:540-573` (dans `_extractGroundTruthSuggestion`)

---

## Statuts de R√©sultat Final

Le service retourne toujours un objet avec `status` et `data` :

### ‚úÖ `verified` - Donn√©es V√©rifi√©es Exactes
**Signification** : Les donn√©es originales sont exactement identiques aux r√©f√©rences trouv√©es.

**Exemple** :
```javascript
{
  status: 'verified',
  data: {
    original: { author: "Alice Ferney", title: "Comme en amour" },
    source: 'babelio',
    confidence_score: 1.0
  }
}
```

### üîÑ `suggestion` - Correction Propos√©e
**Signification** : Le syst√®me propose une modification bas√©e sur ground truth et/ou Babelio.

**Exemple** :
```javascript
{
  status: 'suggestion',
  data: {
    original: { author: "Alain Mabancou", title: "Rams√®s de Paris" },
    suggested: { author: "Alain Mabanckou", title: "Rams√®s de Paris" },
    corrections: { author: true, title: false },
    source: 'babelio',
    confidence_score: 0.95
  }
}
```

### ‚ùì `not_found` - Aucune Suggestion Fiable
**Signification** : Le syst√®me ne peut pas proposer de correction avec confiance suffisante.

**Exemple** :
```javascript
{
  status: 'not_found',
  data: {
    original: { author: "Gr√©gory Lefloc", title: "Peau d'ours" },
    reason: 'no_reliable_match_found',
    attempts: ['ground_truth', 'babelio']
  }
}
```

### ‚ö†Ô∏è `error` - Erreur Technique
**Signification** : Une erreur s'est produite pendant le traitement.

**Exemple** :
```javascript
{
  status: 'error',
  data: {
    original: { author: "...", title: "..." },
    error: 'Timeout: La requ√™te a pris trop de temps',
    attempts: ['babelio']
  }
}
```

---

## Cas d'Usage R√©els Document√©s

### Cas Simples - Succ√®s

#### 1. Validation Directe (Phase 0 uniquement)
**Entr√©e** : Alice Ferney - Comme en amour
**Phase 0** : V√©rification directe Babelio ‚Üí `verified`
**R√©sultat** : ‚úÖ `verified` (source: `babelio_phase0`, workflow termin√© sans fuzzy search)

#### 2. Correction Simple d'Auteur
**Entr√©e** : Alain Mabancou - Rams√®s de Paris
**Ground Truth** : Pas de match fiable
**Babelio** : Sugg√®re "Alain Mabanckou"
**R√©sultat** : üîÑ `suggestion` (auteur corrig√©, titre identique)

#### 3. Ground Truth Perfect Match
**Entr√©e** : Vamille - Fleurs intestinales
**Ground Truth** : Scores 100/98 (perfect)
**Babelio** : Confirme
**R√©sultat** : ‚úÖ `verified` (source: `ground_truth+babelio`)

### Cas Complexes - Cascade

#### 4. Double Correction (Auteur + Titre)
**Entr√©e** : Caroline Dussain - Un d√©ni fran√ßais
**Cascade** :
1. `verifyAuthor("Caroline Dussain")` ‚Üí sugg√®re "Caroline Dawson"
2. `verifyBook("Un d√©ni fran√ßais", "Caroline Dussain")` ‚Üí not_found
3. `verifyBook("Un d√©ni fran√ßais", "Caroline Dawson")` ‚Üí sugg√®re "Caroline du Saint - Un D√©ni fran√ßais - Enqu√™te sur l'√©levage industrie..."

**R√©sultat** : üîÑ `suggestion` (auteur ET titre corrig√©s)

#### 5. Ground Truth avec Faute Orthographique
**Entr√©e** : Emmanuel Carr√®re - Colcause
**Ground Truth** : `titleScore: 35, authorScore: 85` (decent match, author perfect)
**Suggestion** : "Emmanuel Carr√®re - Kolkhoze"
**R√©sultat** : üîÑ `suggestion` (source: `ground_truth`, titre corrig√©)

#### 6. Correction de Casse
**Entr√©e** : Laurent Mauvignier - La Maison Vide
**Babelio** : Sugg√®re "La Maison vide" (casse diff√©rente)
**R√©sultat** : üîÑ `suggestion` (titre avec casse corrig√©e)

### Cas Difficiles - Not Found

#### 7. Inversion de Nom
**Entr√©e** : Gr√©gory Lefloc - Peau d'ours
**Attendu** : Gr√©gory Le Floch - Peau d'ourse
**Ground Truth** : √âchoue (segmentation "Le Floch" probl√©matique)
**Babelio** : √âchoue (ne trouve pas "Lefloc")
**R√©sultat** : ‚ùì `not_found` (n√©cessite intervention manuelle)

#### 8. Pr√©nom Raccourci
**Entr√©e** : Nin Antico - Une Obsession
**Attendu** : Nine Antico - Une obsession
**Probl√®me** : Fuzzy search ne d√©tecte pas "Nin" ‚Üí "Nine"
**R√©sultat** : ‚ùì `not_found` (n√©cessite intervention manuelle)

#### 9. Titre Tr√®s Diff√©rent
**Entr√©e** : Christophe Bigot - Un autre Matin ailleurs
**Attendu** : Christophe Bigot - Un autre m'attend ailleurs
**Probl√®me** : "Matin" vs "m'attend" = faible similarit√©
**R√©sultat** : ‚ùì `not_found` (n√©cessite intervention manuelle)

### Cas Sp√©ciaux - Issue #74

#### 10. Filtrage d'URL
**Entr√©e** : Am√©lie Nothomb - Tant mieux
**Fuzzy Search Brut** :
- `https://www.franceinter.fr/emissions/le-masque-et-la-plume` (score 36) ‚Üí ‚ùå Rejet√©
- `Am√©lie` (score 64) ‚Üí ‚ùå Rejet√© (pr√©nom seul)

**Babelio Fallback** : Confirme "Am√©lie Nothomb - Tant mieux"
**R√©sultat** : ‚úÖ `verified` (source: `babelio`, ground truth filtr√©)

---

## Services Backend Impliqu√©s

### BabelioService (Python)
**Fichier** : `src/back_office_lmelp/services/babelio_service.py`

**Responsabilit√©s** :
- Interrogation API AJAX Babelio (`https://www.babelio.com/aj_recherche.php`)
- Rate limiting (0.8 sec entre requ√™tes)
- Cache disque + m√©moire (performance)
- Calcul de scores de confiance (algorithme Ratcliff-Obershelp)
- Gestion d'erreur robuste (timeout, r√©seau, parsing JSON)

**M√©thodes principales** :
- `search(term)` : Recherche g√©n√©rique Babelio
- `verify_author(name)` : V√©rification auteur
- `verify_book(title, author)` : V√©rification livre
- `verify_batch(items)` : Traitement par lots

**Configuration** :
- Headers + cookies pour √©viter blocages Babelio
- Timeout : 10 sec total, 5 sec connexion
- Cache limite : 100 entr√©es m√©moire, illimit√© disque
- Log verbeux : Variable `BABELIO_CACHE_LOG=1`

### FuzzySearchService (Backend API)
**Fichier** : `src/back_office_lmelp/app.py:583-674`

**Responsabilit√©s** :
- Extraction texte des √©pisodes MongoDB
- Recherche fuzzy avec `rapidfuzz` (Python)
- D√©tection segments entre guillemets (titres probables)
- Calcul scores de similarit√© (0-100)

**Endpoint** : `POST /api/fuzzy-search-episode`

**Param√®tres** :
```json
{
  "episode_id": "68bd9ed3582cf994fb66f1d6",  // pragma: allowlist secret
  "query_title": "Fleurs intestinales",
  "query_author": "Vamille"
}
```

**R√©ponse** :
```json
{
  "found_suggestions": true,
  "title_matches": [["üìñ Fleurs intestinales", 100]],
  "author_matches": [["Vamille", 98]],
  "debug_candidates": ["...", "..."],
  "debug_quoted_matches": ["...", "..."]
}
```

**Algorithme** :
1. Extraire texte : `episode.titre + episode.description`
2. Segments entre guillemets ‚Üí titres prioritaires (marqueur üìñ)
3. Mots > 3 caract√®res ‚Üí candidats g√©n√©raux
4. `rapidfuzz.process.extract()` pour scoring
5. Filtrage par seuils : `titleScore >= 60`, `authorScore >= 75`

---

## Services Frontend Impliqu√©s

### BiblioValidationService (JavaScript)
**Fichier** : `frontend/src/services/BiblioValidationService.js`

**Responsabilit√©s** :
- Orchestration des 4 phases de validation
- Arbitrage intelligent entre sources
- Filtrage suggestions invalides (URLs, fragments)
- Reconstruction noms d'auteurs fragment√©s
- Calcul scores combin√©s (similarit√© + fuzzy)

**M√©thode principale** :
```javascript
async validateBiblio(author, title, publisher, episodeId)
```

**D√©pendances inject√©es** :
- `fuzzySearchService` : Frontend wrapper pour `/api/fuzzy-search-episode`
- `babelioService` : Frontend wrapper pour `/api/verify-babelio`
- `localAuthorService` : Non impl√©ment√© (futur)

**M√©thodes cl√©s** :
- `_tryPhase0DirectValidation()` : Phase 0 (livres extraits)
- `_arbitrateResults()` : Phase 4 (d√©cision finale)
- `_hasGoodGroundTruthMatches()` : D√©tection good matches
- `_hasDecentGroundTruthMatches()` : D√©tection decent matches
- `_extractGroundTruthSuggestion()` : Reconstruction auteur/titre
- `_isValidTitleSuggestion()` : Filtrage URLs/fragments
- `_validateGroundTruthSuggestion()` : Validation ground truth avec Babelio
- `_validateBabelioSuggestion()` : Validation Babelio seule

### BiblioValidationCell (Vue Component)
**Fichier** : `frontend/src/components/BiblioValidationCell.vue`

**Responsabilit√©s** :
- Affichage visuel du statut de validation
- Indicateurs : ‚úÖ Valid√©, üîÑ Suggestion, ‚ùì Non trouv√©, ‚ö†Ô∏è Erreur
- Gestion retry sur erreurs
- Tooltip avec d√©tails

**Props** :
```javascript
{
  author: String,
  title: String,
  publisher: String,
  episodeId: String
}
```

**√âtats** :
- `loading` : Validation en cours
- `result` : R√©sultat de `validateBiblio()`
- `error` : Erreur affich√©e

---

## Configuration et Variables d'Environnement

### Backend (BabelioService)
- `BABELIO_CACHE_LOG` : Verbosit√© des logs cache (`0`/`1`/`true`)
  - `0` (d√©faut) : Logs DEBUG uniquement
  - `1` : Logs INFO pour hit/miss/write

### Rate Limiting
- D√©lai minimum entre requ√™tes Babelio : `0.8 sec`
- Timeout requ√™te Babelio : `10 sec` (total), `5 sec` (connexion)
- Timeout fuzzy search : `30 sec` (configurable dans `api.js`)

### Seuils de Confiance

#### Ground Truth
- **Good matches** : `titleScore >= 80 && authorScore >= 80`
- **Decent matches** : `titleScore >= 75 && authorScore >= 75`
- **Perfect author boost** : Si `authorScore >= 85`, `titleScore >= 35` accept√©

#### Babelio
- **Verified** : `confidence_score >= 0.95`
- **Corrected** : `confidence_score < 0.95`
- **Rejet suggestion fantaisiste** : `confidence_score < 0.8` (sauf livre valid√© + auteur connu)

#### Validation Titre (Filtrage)
- **Longueur minimale** : `>= 3 caract√®res`
- **Mot isol√©** : `>= 8 caract√®res` ou `>= 2 mots`

---

## Tests et Validation

### Tests Backend
- **BabelioService** : Tests unitaires avec mocks API (`tests/test_babelio_service.py`)
- **Fuzzy Search** : Tests int√©gration endpoint (`tests/test_app.py`)
- **Cache** : Tests cache disque/m√©moire (`tests/test_babelio_cache_service.py`)

### Tests Frontend
- **Niveau 1 - UI** : `tests/integration/LivresAuteurs.test.js` (affichage colonne)
- **Niveau 2 - Composant** : `tests/unit/BiblioValidationCell.test.js` (indicateurs visuels)
- **Niveau 3 - Service** : `tests/unit/BiblioValidationService.modular.test.js` (logique arbitrage)
- **Niveau 4 - Backend** : Tests backend s√©par√©s

### Simulation Phase 0 en Tests
**Note importante** : La Phase 0 (`_getExtractedBooks`) utilise actuellement des **fixtures hardcod√©es** pour les tests uniquement :

```javascript
// BiblioValidationService.js:130-138 (CODE DE TEST)
_getExtractedBooks(episodeId) {
  // Simulation bas√©e sur les fixtures pour Alice Ferney
  if (episodeId === '68ab04b92dc760119d18f8ef') {  // pragma: allowlist secret
    return [
      { author: 'Alice Ferney', title: 'Comme en amour' }
    ];
  }
  return [];
}
```

**En production**, cette m√©thode devrait interroger la collection MongoDB `avis_critique` pour r√©cup√©rer les livres r√©ellement extraits de l'√©pisode (champ `summary`).

### Fixtures de Test
**Fichier** : `frontend/tests/fixtures/biblio-validation-cases.yml`

**Structure** :
```yaml
- input:
    author: "Alain Mabancou"
    title: "Rams√®s de Paris"
    publisher: "Seuil"
    episodeId: "68c707ad6e51b9428ab87e9e"  # pragma: allowlist secret
  output:
    status: "suggestion"
    suggested_author: "Alain Mabanckou"
    suggested_title: "Rams√®s de Paris"
    corrections:
      author: true
      title: false
  expected:  # (Optionnel) Pour cas n√©cessitant intervention manuelle
    status: "suggestion"
    suggested_author: "..."
  review:
    manual_review_required: true
    reason: "..."
```

**Cas couverts** :
- ‚úÖ Validated : 2 cas (Alice Ferney, Am√©lie Nothomb)
- üîÑ Suggestion : 5 cas (Mabancou, Dussain, Mauvignier, Pondi, Carr√®re)
- ‚ùì Not Found : 4 cas (Lefloc, Antico, Bigot, Michaud)

---

## Limitations Connues et Am√©liorations Futures

### Limitations Actuelles

1. **Fuzzy Search Fragile**
   - Ne d√©tecte pas les inversions de nom (Le Floch ‚Üí Lefloc)
   - √âchoue sur pr√©noms raccourcis (Nine ‚Üí Nin)
   - Retourne parfois URLs et fragments parasites

2. **Pas de Mapping Canonique**
   - Corrections connues non r√©utilis√©es (recalcul √† chaque fois)
   - Pas de base de donn√©es d'auteurs normalis√©s

3. **Phase 0 Limit√©e**
   - Fixtures hardcod√©es pour tests uniquement
   - Devrait utiliser une vraie API de livres extraits

4. **Babelio Rate Limiting**
   - 0.8 sec entre requ√™tes = lent pour gros volumes
   - Besoin de batch processing optimis√©

### Am√©liorations Propos√©es

#### 1. Mapping Canonique Auteurs
**Fichier** : `data/author-canonical-mapping.yml`

**Structure** :
```yaml
- original: "Gr√©gory Lefloc"
  canonical: "Gr√©gory Le Floch"
  confidence: 1.0
  source: "manual"
  validated_at: "2025-09-07"
```

**Avantages** :
- √âvite de recalculer les cas difficiles
- Base de connaissances r√©utilisable
- Intervention humaine document√©e

#### 2. Recherche par Auteur Babelio First
**Workflow alternatif** :
1. Chercher l'auteur sur Babelio
2. R√©cup√©rer sa bibliographie compl√®te
3. Fuzzy match le titre dans sa bibliographie
4. √âvite les faux positifs (homonymes)

**Cas b√©n√©ficiaires** : Christophe Bigot, Agn√®s Michaux

#### 3. Am√©lioration Fuzzy Search Backend
**Techniques** :
- D√©tection phon√©tique (Soundex, Metaphone pour fran√ßais)
- N-grams pour variantes orthographiques
- NER (Named Entity Recognition) pour extraction auteurs/titres
- Fine-tuning seuils adaptatifs par type d'erreur

#### 4. Service Local Auteurs
**Base MongoDB** : Collection `auteurs_canoniques`

**Workflow** :
1. V√©rifier cache local d'abord
2. Fallback Babelio si absent
3. Mise √† jour cache apr√®s validation manuelle

**Avantages** :
- Z√©ro latence r√©seau pour auteurs connus
- Contr√¥le complet sur mapping
- Ind√©pendance vis-√†-vis Babelio

---

## Debugging et Monitoring

### Logs de Debug

#### Backend (BabelioService)
**Activation** : `BABELIO_CACHE_LOG=1 python -m back_office_lmelp.app`

**Exemple** :
```
[BabelioCache] MISS keys=(orig='Alain Mabancou', norm='alain mabancou')
[BabelioCache] WROTE keys=(orig='Alain Mabancou', norm='alain mabancou') items=3
[BabelioCache] HIT (orig) key='Alain Mabancou' items=3 ts=1640995200.0
```

#### Frontend (Console)
**Tests** : `npm test -- BiblioValidation --reporter verbose`

**Browser** : Console DevTools affiche les appels API

### Fixture Capture (Tests)
**Service** : `FixtureCaptureService.js`

**Activation** :
```javascript
import { fixtureCaptureService } from './FixtureCaptureService.js';

fixtureCaptureService.startCapture();
await validateBiblio(...);
const fixtures = fixtureCaptureService.stopCapture();
console.log(JSON.stringify(fixtures, null, 2));
```

**Utile pour** :
- Capturer r√©ponses API r√©elles
- G√©n√©rer fixtures de test automatiquement
- Reproduire bugs en environnement contr√¥l√©

---

## R√©f√©rences

### Documentation
- [Validation Biblio Tests](validation-biblio-tests.md) : Architecture tests hi√©rarchiques
- Fixtures YAML : `frontend/tests/fixtures/biblio-validation-cases.yml` (cas de test r√©els)

### Code Source Principal
- **Backend** :
  - `src/back_office_lmelp/services/babelio_service.py` : Service Babelio
  - `src/back_office_lmelp/app.py:583-674` : Endpoint fuzzy search
- **Frontend** :
  - `frontend/src/services/BiblioValidationService.js` : Orchestration
  - `frontend/src/components/BiblioValidationCell.vue` : Composant affichage

### Issues GitHub
- [Issue #74](https://github.com/castorfou/back-office-lmelp/issues/74) : Filtrage URLs/fragments
- [Issue #68](https://github.com/castorfou/back-office-lmelp/issues/68) : Phase 0 livres extraits
- [Issue #66](https://github.com/castorfou/back-office-lmelp/issues/66) : Collections management

---

## Glossaire

- **Ground Truth** : Donn√©es de r√©f√©rence extraites des transcriptions d'√©pisodes (titre + description)
- **Fuzzy Search** : Recherche approximative tol√©rant les fautes d'orthographe (algorithme Levenshtein/rapidfuzz)
- **Babelio** : Site web de r√©f√©rence bibliographique fran√ßais (source de v√©rit√© externe)
- **Confidence Score** : Score de confiance 0.0-1.0 mesurant la similarit√© entre donn√©es originales et suggestions
- **Rate Limiting** : Limitation du nombre de requ√™tes par seconde pour respecter les serveurs externes
- **Arbitrage** : Processus de d√©cision combinant plusieurs sources de donn√©es pour choisir la meilleure suggestion
- **Phase 0** : Validation directe des livres extraits (nouveau workflow Issue #68)
- **Not Found** : Statut indiquant qu'aucune suggestion fiable n'a pu √™tre trouv√©e (n√©cessite intervention manuelle)

# Service de V√©rification Bibliographique - Architecture et Flux de Traitement

## Vue d'ensemble

Le syst√®me de v√©rification bibliographique est un service multi-phase qui valide et corrige automatiquement les donn√©es bibliographiques (auteur, titre, √©diteur) extraites des avis critiques du Masque et la Plume.

**Contexte** : Les livres √† corriger proviennent de la collection MongoDB `avis_critique` (champ `summary`), g√©n√©r√©e depuis la transcription audio Whisper. Cette transcription automatique introduit des erreurs orthographiques que le service doit corriger.

**Donn√©es d'entr√©e** : Livres extraits des avis critiques (collection MongoDB `avis_critique`, champ `summary`), g√©n√©r√©s depuis la transcription audio Whisper.

Le service utilise **deux sources de validation** pour maximiser la fiabilit√© :

1. **Babelio** (API externe) - Base de donn√©es bibliographique de r√©f√©rence
2. **M√©tadonn√©es √©pisodes** (MongoDB `episodes`) - Donn√©es √©ditorialis√©es France Inter (champs `titre` + `description`)

Le workflow se d√©compose en **trois phases successives** :

- **Phase 0** : Validation directe Babelio des livres extraits (avec enrichissements : double appel, correction auteur)
- **Phase 1** : Fuzzy search dans les m√©tadonn√©es √©ditorialis√©es de l'√©pisode
- **Phase 2** : Validation Babelio compl√®te (auteur + livre) avec cascade de recherches

## Architecture G√©n√©rale

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ    DONN√âES D'ENTR√âE          ‚îÇ
                    ‚îÇ  Livres extraits avis_       ‚îÇ
                    ‚îÇ  critique (Whisper)          ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚îÇ
                                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    BiblioValidationService                          ‚îÇ
‚îÇ                    (Frontend - Orchestration)                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                         ‚îÇ                         ‚îÇ
         ‚ñº                         ‚ñº                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    Phase 0      ‚îÇ    ‚îÇ     Phase 1      ‚îÇ    ‚îÇ      Phase 2        ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                  ‚îÇ    ‚îÇ                     ‚îÇ
‚îÇ Validation      ‚îÇ    ‚îÇ Fuzzy Search     ‚îÇ    ‚îÇ Validation Babelio  ‚îÇ
‚îÇ Babelio directe ‚îÇ    ‚îÇ (Ground Truth)   ‚îÇ    ‚îÇ compl√®te            ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                  ‚îÇ    ‚îÇ                     ‚îÇ
‚îÇ - Livres        ‚îÇ    ‚îÇ Backend API      ‚îÇ    ‚îÇ External API        ‚îÇ
‚îÇ   extraits      ‚îÇ    ‚îÇ /api/fuzzy-      ‚îÇ    ‚îÇ /api/verify-        ‚îÇ
‚îÇ - Double appel  ‚îÇ    ‚îÇ search-episode   ‚îÇ    ‚îÇ babelio             ‚îÇ
‚îÇ - Correction    ‚îÇ    ‚îÇ                  ‚îÇ    ‚îÇ                     ‚îÇ
‚îÇ   auteur        ‚îÇ    ‚îÇ Sources:         ‚îÇ    ‚îÇ - verifyAuthor()    ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ - episode.titre  ‚îÇ    ‚îÇ - verifyBook()      ‚îÇ
‚îÇ Source:         ‚îÇ    ‚îÇ - episode.       ‚îÇ    ‚îÇ - Cascade           ‚îÇ
‚îÇ Babelio API     ‚îÇ    ‚îÇ   description    ‚îÇ    ‚îÇ                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                         ‚îÇ                         ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚îÇ
                                   ‚ñº
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ   Arbitration    ‚îÇ
                         ‚îÇ                  ‚îÇ
                         ‚îÇ - Priority rules ‚îÇ
                         ‚îÇ - Confidence     ‚îÇ
                         ‚îÇ   scoring        ‚îÇ
                         ‚îÇ - Filtering      ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚îÇ
                                   ‚ñº
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ  Final Result    ‚îÇ
                         ‚îÇ                  ‚îÇ
                         ‚îÇ - verified       ‚îÇ
                         ‚îÇ - suggestion     ‚îÇ
                         ‚îÇ - not_found      ‚îÇ
                         ‚îÇ - error          ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

SOURCES DE VALIDATION :
1. Babelio API (Phases 0 & 2)
2. M√©tadonn√©es √©pisodes MongoDB (Phase 1)
```

## Flux de Traitement D√©taill√©

### Phase 0 : Validation Directe Babelio avec Enrichissements

**Objectif** : Pour chaque couple auteur-livre √† valider, effectuer une **v√©rification directe sur Babelio** des livres extraits de l'√©pisode avant toute autre tentative. Phase 0 inclut deux m√©canismes d'enrichissement pour maximiser le taux de succ√®s :

1. **Double appel de confirmation** : Si Babelio sugg√®re une correction avec confidence 0.85-0.99, un 2√®me appel confirme la suggestion
2. **Correction automatique d'auteur** : Si le livre n'est pas trouv√©, Phase 0 essaie de corriger l'auteur avant de passer en Phase 1

**Processus complet** :
1. R√©cup√©rer les livres extraits de l'√©pisode via `livresAuteursService.getLivresAuteurs({ episode_oid: episodeId })`
2. V√©rifier si l'input utilisateur correspond exactement √† un livre extrait
3. **Si match trouv√©**, appeler Babelio : `verifyBook(title, author)`
4. **Selon la r√©ponse Babelio**, appliquer les enrichissements (d√©tails ci-dessous)
5. **Si succ√®s** ‚Üí ‚úÖ **Termin√©, retourner r√©sultat**
6. **Si √©chec** ‚Üí ‚ùå **Passer √† Phase 1** (fuzzy search)

**Fonctionnement de `verifyBook()` :**
- Recherche le livre sur Babelio avec fuzzy matching (tol√®re les fautes d'orthographe)
- Calcule un `confidence_score` (0.0 √† 1.0) bas√© sur la similarit√© des cha√Ænes (algorithme Ratcliff-Obershelp)
- Retourne un statut selon le seuil de confiance :
  - **`verified`** si `confidence_score >= 0.90` (correspondance quasi-exacte)
  - **`corrected`** si `confidence_score < 0.90` (suggestion de correction)
  - **`not_found`** si aucun livre trouv√© sur Babelio

#### Enrichissement 1 : Double Appel de Confirmation

**Sc√©nario** : Babelio retourne `status: 'verified'` ou `'corrected'` avec `confidence_score` entre 0.85 et 0.99

**Workflow** :
1. **1er appel** : `verifyBook(title, author)` retourne suggestion avec confidence 0.85-0.99
2. **D√©tection** : Le score n'est pas assez √©lev√© (< 1.0) pour valider directement
3. **2√®me appel** : `verifyBook(suggested_title, suggested_author)` avec les valeurs sugg√©r√©es
4. **Si le 2√®me appel confirme avec confidence 1.0** :
   - ‚úÖ Retourner `status: 'verified'`
   - Source : `babelio_phase0_confirmed`
   - Confidence : 1.0
5. **Si le 2√®me appel ne confirme pas** :
   - ‚ùå Fallback Phase 1 (fuzzy search)

**Exemple concret** :
```javascript
// Input utilisateur
author: "Adrien Bosque"  // Erreur de transcription Whisper
title: "L'invention de Tristan"

// Livre extrait en base (m√™me erreur)
{ auteur: "Adrien Bosque", titre: "L'invention de Tristan" }

// 1er appel Babelio
verifyBook("L'invention de Tristan", "Adrien Bosque")
‚Üí status: 'verified', confidence: 0.95
‚Üí babelio_suggestion_author: "Adrien Bosc"  // Correction d√©tect√©e

// 2√®me appel de confirmation
verifyBook("L'invention de Tristan", "Adrien Bosc")
‚Üí status: 'verified', confidence: 1.0  // Confirmation !

// R√©sultat Phase 0
{
  status: 'verified',
  data: {
    source: 'babelio_phase0_confirmed',
    confidence_score: 1.0,
    suggested: {
      author: "Adrien Bosc",
      title: "L'invention de Tristan"
    },
    corrections: { author: true, title: false }
  }
}
```

**Avantage** : Permet de corriger automatiquement les erreurs de transcription Whisper m√™me quand Babelio n'est pas s√ªr √† 100% au premier appel.

#### Enrichissement 2 : Correction Automatique d'Auteur

**Sc√©nario** : Babelio retourne `status: 'not_found'` (livre non trouv√©)

**Hypoth√®se** : Le probl√®me vient de l'orthographe de l'auteur, pas du titre

**Workflow** :
1. **1er appel livre** : `verifyBook(title, author)` ‚Üí `not_found`
2. **D√©tection** : Aucun livre trouv√©, possiblement √† cause de l'auteur
3. **Appel auteur** : `verifyAuthor(author)` pour obtenir suggestion d'auteur corrig√©
4. **Si suggestion d'auteur obtenue** :
   - 2√®me appel livre : `verifyBook(title, corrected_author)`
5. **Si le 2√®me appel livre r√©ussit avec confidence 1.0** :
   - ‚úÖ Retourner `status: 'verified'`
   - Source : `babelio_phase0_author_correction`
   - Confidence : 1.0
6. **Si le 2√®me appel livre √©choue** :
   - ‚ùå Fallback Phase 1 (fuzzy search)

**Exemple concret** :
```javascript
// Input utilisateur
author: "Fabrice Caro"  // Erreur de transcription Whisper
title: "Rumba Mariachi"

// Livre extrait en base (m√™me erreur)
{ auteur: "Fabrice Caro", titre: "Rumba Mariachi" }

// 1er appel livre
verifyBook("Rumba Mariachi", "Fabrice Caro")
‚Üí status: 'not_found'  // Livre inconnu avec cet auteur

// Appel auteur pour correction
verifyAuthor("Fabrice Caro")
‚Üí status: 'corrected', confidence: 0.73
‚Üí babelio_suggestion: "Fabcaro"  // Vrai nom de l'auteur

// 2√®me appel livre avec auteur corrig√©
verifyBook("Rumba Mariachi", "Fabcaro")
‚Üí status: 'verified', confidence: 1.0  // Livre trouv√© !

// R√©sultat Phase 0
{
  status: 'verified',
  data: {
    source: 'babelio_phase0_author_correction',
    confidence_score: 1.0,
    suggested: {
      author: "Fabcaro",
      title: "Rumba Mariachi"
    },
    corrections: { author: true, title: false }
  }
}
```

**Avantage** : Traite automatiquement le cas fr√©quent o√π seul le nom d'auteur est mal orthographi√© (noms propres complexes, transcription audio difficile).

#### Cas de Succ√®s Phase 0 (Sans Enrichissement)

**Sc√©nario simple** : Babelio confirme directement avec `confidence_score >= 1.0`

**Workflow** :
1. **Appel unique** : `verifyBook(title, author)` ‚Üí `status: 'verified'`, `confidence: 1.0`
2. ‚úÖ Retourner `status: 'verified'` imm√©diatement
3. Source : `babelio_phase0`

**Conditions de succ√®s** :
- Babelio retourne `status: 'verified'` ET `confidence_score >= 1.0`

**Conditions d'√©chec (passage Phase 1)** :
- Erreur r√©seau ou timeout
- Tous les enrichissements ont √©chou√©

**Code source** :
- Frontend : `BiblioValidationService.js:80-216` (`_tryPhase0DirectValidation`)
- Backend API : `/api/verify-babelio` (endpoint Babelio)
- Backend API : `/api/livres-auteurs` (livres extraits)

**Exemple de succ√®s** :
```javascript
// Entr√©e (donn√©es extraites de avis_critique.summary via Whisper)
author: "Am√©lie Nothomb"
title: "Tant mieux"
episodeId: "68d98f74edbcf1765933a9b5"  // pragma: allowlist secret

// Phase 0 : V√©rification directe Babelio
verifyBook("Tant mieux", "Am√©lie Nothomb")
‚Üí status: 'verified', confidence: 1.0
‚Üí Babelio confirme : ces donn√©es sont exactes

// R√©sultat Phase 0 (termin√©)
{
  status: 'verified',
  data: {
    source: 'babelio_phase0',
    confidence_score: 1.0
  }
}
// ‚úÖ Pas besoin de fuzzy search, workflow termin√©
```

---

### Phase 1 : Ground Truth Fuzzy Search

**Objectif** : Rechercher les donn√©es bibliographiques dans les **m√©tadonn√©es √©ditorialis√©es** de l'√©pisode (champs `titre` + `description` v√©rifi√©s par l'√©diteur France Inter).

**Important** : Cette recherche ne se fait **pas** sur la transcription audio brute, mais sur les m√©tadonn√©es MongoDB de la collection `episodes` qui sont des donn√©es fiables et √©ditorialis√©es.

**Exemple de document `episodes` MongoDB** :
```json
{
  "_id": "68d98f74edbcf1765933a9b5",
  "titre": "Catherine Millet, Sorj Chalandon, Rebeka Warrior, Am√©lie Nothomb...",
  "description": "Le nouveau texte de Sigrid Nunez ou encore celui d'Am√©lie Nothomb sur sa m√®re...",
  "type": "livres",
  "date": "2025-09-28T10:59:39.000Z"
}
```

**Processus** :
1. Appel API : `POST /api/fuzzy-search-episode`
   ```javascript
   {
     episode_id: "68bd9ed3582cf994fb66f1d6",  // pragma: allowlist secret
     query_title: "Fleurs intestinales",
     query_author: "Vamille"
   }
   ```

2. Backend extrait les m√©tadonn√©es de l'√©pisode :
   - R√©cup√©ration depuis MongoDB (`episodes` collection)
   - Combinaison des champs `titre` + `description` (donn√©es √©ditorialis√©es)
   - Extraction des segments entre guillemets (priorit√© haute pour titres)
   - Extraction des mots > 3 caract√®res

3. Recherche fuzzy avec `rapidfuzz` (Python) :
   - **Titres** : Recherche dans segments entre guillemets (marqueur üìñ) + mots g√©n√©raux
   - **Auteurs** : Recherche dans tous les candidats textuels
   - Scores de similarit√© calcul√©s (0-100)

4. R√©ponse API :
   ```javascript
   {
     found_suggestions: true,
     title_matches: [
       ["üìñ Fleurs intestinales", 100],
       ["intestinales", 75]
     ],
     author_matches: [
       ["Vamille", 98]
     ]
   }
   ```

**Seuils de qualit√©** :
- **Good matches** : `titleScore >= 80 && authorScore >= 80`
- **Decent matches** : `titleScore >= 75 && authorScore >= 75` (assoupli pour variantes)
- **Perfect author boost** : Si `authorScore >= 85`, seuil titre r√©duit √† 35

**Code source** :
- Backend : `app.py:583-674` (endpoint `/api/fuzzy-search-episode`)
- Frontend : `BiblioValidationService.js:426-518` (`_hasGoodGroundTruthMatches`, `_hasDecentGroundTruthMatches`)

**Limites connues** :
- Peut retourner des **URLs** : `https://www.franceinter.fr/...` (pr√©sentes dans le champ `description`)
- Peut retourner des **fragments trop courts** : `am`, `de`, `Am√©lie`
- N√©cessite filtrage avant utilisation (voir Phase 4)

**Note** : Le fuzzy search √©choue parfois car les m√©tadonn√©es `titre` et `description` ne contiennent pas toujours les noms complets ou corrects des auteurs/titres (contrairement aux donn√©es Babelio qui sont normalis√©es).

**Origine des donn√©es √† corriger** :
Les livres/auteurs √† valider proviennent de la collection `avis_critique` (champ `summary`), qui est g√©n√©r√©e depuis la **transcription audio Whisper**. C'est cette transcription automatique qui introduit les erreurs orthographiques (ex: "Alain Mabancou" au lieu de "Mabanckou").

---

### Phase 2 : Validation Babelio de l'Auteur

**Objectif** : V√©rifier et corriger l'orthographe de l'auteur via l'API AJAX de Babelio.

**Processus** :
1. Appel API : `POST /api/verify-babelio`
   ```javascript
   {
     type: "author",
     name: "Alain Mabancou"  // Faute d'orthographe
   }
   ```

2. Backend interroge Babelio :
   - Endpoint : `https://www.babelio.com/aj_recherche.php`
   - Rate limiting : 0.8 sec entre requ√™tes
   - Cache disque + m√©moire pour performances
   - Headers/cookies appropri√©s pour √©viter blocages

3. R√©ponse Babelio (via BabelioService) :
   ```javascript
   {
     status: "corrected",  // ou "verified" si exact
     original: "Alain Mabancou",
     babelio_suggestion: "Alain Mabanckou",
     confidence_score: 0.95,
     babelio_data: {
       id: "2180",
       prenoms: "Alain",
       nom: "Mabanckou",
       type: "auteurs",
       ca_membres: "30453"
     },
     babelio_url: "https://www.babelio.com/auteur/Alain-Mabanckou/2180"
   }
   ```

**Statuts possibles** :
- `verified` : Orthographe exacte confirm√©e (`confidence_score >= 0.95`)
- `corrected` : Suggestion de correction (`confidence_score < 0.95`)
- `not_found` : Aucun auteur trouv√©
- `error` : Erreur technique (timeout, r√©seau, etc.)

**Code source** :
- Backend : `babelio_service.py:317-379` (`verify_author`)
- Scoring : `babelio_service.py:570-586` (`_calculate_similarity` - algorithme Ratcliff-Obershelp)

---

### Phase 3 : Validation Babelio du Livre

**Objectif** : V√©rifier et corriger le titre du livre, en tenant compte de la suggestion d'auteur.

**Processus** :
1. **Strat√©gie intelligente** (BiblioValidationService) :
   - Si Phase 2 sugg√®re une correction d'auteur :
     - Essayer d'abord avec l'auteur **original**
     - Si √©chec (`not_found`), r√©essayer avec l'auteur **sugg√©r√©**
   - Sinon, tester uniquement avec l'auteur original

2. Appel API : `POST /api/verify-babelio`
   ```javascript
   {
     type: "book",
     title: "Rams√®s de Paris",
     author: "Alain Mabanckou"  // Auteur corrig√© de Phase 2
   }
   ```

3. R√©ponse Babelio :
   ```javascript
   {
     status: "verified",
     original_title: "Rams√®s de Paris",
     babelio_suggestion_title: "Rams√®s de Paris",
     original_author: "Alain Mabanckou",
     babelio_suggestion_author: "Alain Mabanckou",
     confidence_score: 1.0,
     babelio_data: {
       id_oeuvre: "1770",
       titre: "Rams√®s de Paris",
       prenoms: "Alain",
       nom: "Mabanckou",
       type: "livres"
     }
   }
   ```

**Cascade de recherche** (exemple complexe - Caroline Dussain) :
```
1. verifyAuthor("Caroline Dussain")
   ‚Üí sugg√®re "Caroline Dawson" (confidence: 0.82)

2. verifyBook("Un d√©ni fran√ßais", "Caroline Dussain")
   ‚Üí not_found

3. verifyBook("Un d√©ni fran√ßais", "Caroline Dawson")
   ‚Üí sugg√®re "Caroline du Saint - Un D√©ni fran√ßais - Enqu√™te sur l'√©levage industrie..."
   ‚Üí (confidence: 0.88)

R√©sultat final: Caroline du Saint - Un D√©ni fran√ßais - Enqu√™te...
```

**Code source** :
- Backend : `babelio_service.py:380-461` (`verify_book`)
- Frontend : `BiblioValidationService.js:188-242` (logique de cascade)
- Scoring : Combin√© (70% titre + 30% auteur) pour livres

---

### Phase 4 : Arbitrage et D√©cision Finale

**Objectif** : Combiner les r√©sultats des 3 sources avec r√®gles de priorit√© et filtrage intelligent.

#### 4.1 Filtrage des Suggestions Invalides

**Avant l'arbitrage**, filtrer les suggestions ground truth invalides via `_isValidTitleSuggestion()` :

**R√®gles de rejet** :
- URLs compl√®tes : `http://`, `https://`, `www.`, `franceinter.fr`, `.com`, `.fr`
- Fragments trop courts : `< 3 caract√®res` (sauf si exact match avec original)
- Mots isol√©s courts : `< 8 caract√®res` pour un seul mot (filtre "Am√©lie", "tous", etc.)

**Exemple de filtrage** :
```javascript
// Entr√©e fuzzy search
titleMatches: [
  ["üìñ https://www.franceinter.fr/emissions/le-masque", 36],  // ‚ùå URL
  ["üìñ Am√©lie", 64],                                          // ‚ùå Pr√©nom seul
  ["üìñ Tant mieux", 92]                                       // ‚úÖ Valide
]

// Apr√®s filtrage
titleMatches: [
  ["üìñ Tant mieux", 92]  // Seule suggestion gard√©e
]
```

**Code source** : `BiblioValidationService.js:697-728` (`_isValidTitleSuggestion`)

#### 4.2 Ordre de Priorit√© des Sources

**R√®gle 1 : Ground Truth avec Good Matches** (priorit√© absolue)
- **Conditions** : `titleScore >= 80 && authorScore >= 80` + suggestion valide
- **Action** : Utiliser la suggestion ground truth
- **Validation** : V√©rifier coh√©rence avec Babelio si possible
- **Exemple** : Vamille - Fleurs intestinales (scores 100/98)

**R√®gle 2 : Ground Truth avec Decent Matches** (priorit√© forte)
- **Conditions** : `titleScore >= 75 && authorScore >= 75` + suggestion valide
- **Cas sp√©cial** : Si `authorScore >= 85`, accepter `titleScore >= 35`
- **Action** : Utiliser ground truth **sans exiger confirmation Babelio**
- **Exemple** : Emmanuel Carr√®re - Colcause ‚Üí Kolkhoze (scores 85/35)

**R√®gle 3 : Validation Directe Babelio** (pas de suggestion)
- **Conditions** :
  - `authorValidation.status === 'verified'` ET pas de suggestion d'auteur
  - `bookValidation.status === 'verified'`
  - Pas de ground truth utilisable
- **Action** : Retourner `status: 'verified'` (donn√©es originales exactes)
- **Exemple** : Alice Ferney - Comme en amour

**R√®gle 4 : Suggestion Babelio Seule**
- **Conditions** : Babelio propose une correction (`status: 'corrected'` ou `'verified'` avec diff√©rence)
- **Filtrage** : Rejeter si `confidence_score < 0.8` (sauf si livre valid√© + auteur connu)
- **Action** : Retourner `status: 'suggestion'` avec donn√©es Babelio
- **Exemple** : Alain Mabancou ‚Üí Alain Mabanckou

**R√®gle 5 : Not Found** (aucune source fiable)
- **Conditions** : Aucune des r√®gles ci-dessus ne s'applique
- **Action** : Retourner `status: 'not_found'`
- **Exemples** : Gr√©gory Lefloc - Peau d'ours (n√©cessite intervention manuelle)

**Code source** : `BiblioValidationService.js:293-420` (`_arbitrateResults`)

#### 4.3 Reconstruction du Nom d'Auteur (Ground Truth)

Lorsque ground truth retourne des **fragments d'auteur** (ex: `["Alikavazovic", 82], ["Jakuta", 78]`), le service reconstruit le nom complet :

**Algorithme de reconstruction** :
1. Filtrer les mots parasites : `pour`, `de`, `du`, `la`, `le`, `et`, `dans`, etc.
2. Nettoyer les fragments : enlever `d'`, `l'`, `de ` du d√©but
3. Identifier pr√©nom vs nom :
   - Heuristique longueur (pr√©nom g√©n√©ralement plus court)
   - D√©tection pattern majuscule + minuscules
   - Unicode-aware pour noms accentu√©s
4. Ordre final : `Pr√©nom Nom`

**Exemple** :
```javascript
// Entr√©e fuzzy
authorMatches: [
  ["Alikavazovic", 82],
  ["Jakuta", 78],
  ["pour", 65]  // Bruit
]

// Apr√®s reconstruction
reconstructedAuthor: "Jakuta Alikavazovic"
// Jakuta (plus court, pattern pr√©nom) + Alikavazovic (nom)
```

**Code source** : `BiblioValidationService.js:524-690` (`_extractGroundTruthSuggestion`)

#### 4.4 Priorisation des Titres (Ground Truth)

Lorsque fuzzy search retourne **plusieurs titres candidats**, le service utilise un score combin√© :

**Algorithme de scoring** :
1. Calculer **similarit√© Levenshtein** entre titre original et candidat (normalis√© 0-1)
2. Normaliser **score fuzzy** de rapidfuzz (0-1)
3. Score combin√© : `similarit√© √ó 0.7 + score_fuzzy √ó 0.3`
4. Filtrer les suggestions invalides (URLs, fragments)
5. Trier par score combin√© d√©croissant
6. Retourner le meilleur match

**Exemple** :
```javascript
// Entr√©e
original.title: "Colcause"

titleMatches: [
  ["üìñ Kolkhoze", 75],      // Similarit√©: 0.85 ‚Üí combin√©: 0.82
  ["üìñ Kolkhoz", 78],       // Similarit√©: 0.80 ‚Üí combin√©: 0.79
  ["cause", 90]             // Similarit√©: 0.50 ‚Üí combin√©: 0.62
]

// R√©sultat : "Kolkhoze" (meilleur compromis similarit√©/score)
```

**Code source** : `BiblioValidationService.js:540-573` (dans `_extractGroundTruthSuggestion`)

---

## Statuts de R√©sultat Final

Le service retourne toujours un objet avec `status` et `data` :

### ‚úÖ `verified` - Donn√©es V√©rifi√©es Exactes
**Signification** : Les donn√©es originales sont exactement identiques aux r√©f√©rences trouv√©es (ou ont √©t√© corrig√©es et confirm√©es).

**Sources possibles** :
- `babelio_phase0` : Validation directe sans enrichissement (confidence 1.0)
- `babelio_phase0_confirmed` : Double appel de confirmation (1er appel 0.85-0.99, 2√®me appel 1.0)
- `babelio_phase0_author_correction` : Correction automatique d'auteur (livre trouv√© apr√®s correction auteur)
- `babelio` : Validation via Phases 2-3 (workflow complet)
- `ground_truth+babelio` : Validation combin√©e fuzzy search + Babelio

**Exemples** :
```javascript
// Validation directe Phase 0
{
  status: 'verified',
  data: {
    original: { author: "Alice Ferney", title: "Comme en amour" },
    source: 'babelio_phase0',
    confidence_score: 1.0
  }
}

// Double appel de confirmation
{
  status: 'verified',
  data: {
    original: { author: "Adrien Bosque", title: "L'invention de Tristan" },
    suggested: { author: "Adrien Bosc", title: "L'invention de Tristan" },
    source: 'babelio_phase0_confirmed',
    confidence_score: 1.0,
    corrections: { author: true, title: false }
  }
}

// Correction automatique d'auteur
{
  status: 'verified',
  data: {
    original: { author: "Fabrice Caro", title: "Rumba Mariachi" },
    suggested: { author: "Fabcaro", title: "Rumba Mariachi" },
    source: 'babelio_phase0_author_correction',
    confidence_score: 1.0,
    corrections: { author: true, title: false }
  }
}
```

### üîÑ `suggestion` - Correction Propos√©e
**Signification** : Le syst√®me propose une modification bas√©e sur ground truth et/ou Babelio.

**Exemple** :
```javascript
{
  status: 'suggestion',
  data: {
    original: { author: "Alain Mabancou", title: "Rams√®s de Paris" },
    suggested: { author: "Alain Mabanckou", title: "Rams√®s de Paris" },
    corrections: { author: true, title: false },
    source: 'babelio',
    confidence_score: 0.95
  }
}
```

### ‚ùì `not_found` - Aucune Suggestion Fiable
**Signification** : Le syst√®me ne peut pas proposer de correction avec confiance suffisante.

**Exemple** :
```javascript
{
  status: 'not_found',
  data: {
    original: { author: "Gr√©gory Lefloc", title: "Peau d'ours" },
    reason: 'no_reliable_match_found',
    attempts: ['ground_truth', 'babelio']
  }
}
```

### ‚ö†Ô∏è `error` - Erreur Technique
**Signification** : Une erreur s'est produite pendant le traitement.

**Exemple** :
```javascript
{
  status: 'error',
  data: {
    original: { author: "...", title: "..." },
    error: 'Timeout: La requ√™te a pris trop de temps',
    attempts: ['babelio']
  }
}
```

---

## Cas d'Usage R√©els Document√©s

### Cas Simples - Succ√®s

#### 1. Validation Directe (Phase 0 uniquement)
**Entr√©e** : Alice Ferney - Comme en amour
**Phase 0** : V√©rification directe Babelio ‚Üí `verified`
**R√©sultat** : ‚úÖ `verified` (source: `babelio_phase0`, workflow termin√© sans fuzzy search)

#### 2. Correction Simple d'Auteur
**Entr√©e** : Alain Mabancou - Rams√®s de Paris
**Ground Truth** : Pas de match fiable
**Babelio** : Sugg√®re "Alain Mabanckou"
**R√©sultat** : üîÑ `suggestion` (auteur corrig√©, titre identique)

#### 3. Ground Truth Perfect Match
**Entr√©e** : Vamille - Fleurs intestinales
**Ground Truth** : Scores 100/98 (perfect)
**Babelio** : Confirme
**R√©sultat** : ‚úÖ `verified` (source: `ground_truth+babelio`)

### Cas Complexes - Cascade

#### 4. Double Correction (Auteur + Titre)
**Entr√©e** : Caroline Dussain - Un d√©ni fran√ßais
**Cascade** :
1. `verifyAuthor("Caroline Dussain")` ‚Üí sugg√®re "Caroline Dawson"
2. `verifyBook("Un d√©ni fran√ßais", "Caroline Dussain")` ‚Üí not_found
3. `verifyBook("Un d√©ni fran√ßais", "Caroline Dawson")` ‚Üí sugg√®re "Caroline du Saint - Un D√©ni fran√ßais - Enqu√™te sur l'√©levage industrie..."

**R√©sultat** : üîÑ `suggestion` (auteur ET titre corrig√©s)

#### 5. Ground Truth avec Faute Orthographique
**Entr√©e** : Emmanuel Carr√®re - Colcause
**Ground Truth** : `titleScore: 35, authorScore: 85` (decent match, author perfect)
**Suggestion** : "Emmanuel Carr√®re - Kolkhoze"
**R√©sultat** : üîÑ `suggestion` (source: `ground_truth`, titre corrig√©)

#### 6. Correction de Casse
**Entr√©e** : Laurent Mauvignier - La Maison Vide
**Babelio** : Sugg√®re "La Maison vide" (casse diff√©rente)
**R√©sultat** : üîÑ `suggestion` (titre avec casse corrig√©e)

### Cas Difficiles - Not Found

#### 7. Inversion de Nom
**Entr√©e** : Gr√©gory Lefloc - Peau d'ours
**Attendu** : Gr√©gory Le Floch - Peau d'ourse
**Ground Truth** : √âchoue (segmentation "Le Floch" probl√©matique)
**Babelio** : √âchoue (ne trouve pas "Lefloc")
**R√©sultat** : ‚ùì `not_found` (n√©cessite intervention manuelle)

#### 8. Pr√©nom Raccourci
**Entr√©e** : Nin Antico - Une Obsession
**Attendu** : Nine Antico - Une obsession
**Probl√®me** : Fuzzy search ne d√©tecte pas "Nin" ‚Üí "Nine"
**R√©sultat** : ‚ùì `not_found` (n√©cessite intervention manuelle)

#### 9. Titre Tr√®s Diff√©rent
**Entr√©e** : Christophe Bigot - Un autre Matin ailleurs
**Attendu** : Christophe Bigot - Un autre m'attend ailleurs
**Probl√®me** : "Matin" vs "m'attend" = faible similarit√©
**R√©sultat** : ‚ùì `not_found` (n√©cessite intervention manuelle)

### Cas Sp√©ciaux - Filtrage URLs et Fragments

#### 10. Filtrage d'URL
**Entr√©e** : Am√©lie Nothomb - Tant mieux
**Fuzzy Search Brut** :
- `https://www.franceinter.fr/emissions/le-masque-et-la-plume` (score 36) ‚Üí ‚ùå Rejet√©
- `Am√©lie` (score 64) ‚Üí ‚ùå Rejet√© (pr√©nom seul)

**Babelio Fallback** : Confirme "Am√©lie Nothomb - Tant mieux"
**R√©sultat** : ‚úÖ `verified` (source: `babelio`, ground truth filtr√©)

---

## Services Backend Impliqu√©s

### BabelioService (Python)
**Fichier** : `src/back_office_lmelp/services/babelio_service.py`

**Responsabilit√©s** :
- Interrogation API AJAX Babelio (`https://www.babelio.com/aj_recherche.php`)
- Rate limiting (0.8 sec entre requ√™tes)
- Cache disque + m√©moire (performance)
- Calcul de scores de confiance (algorithme Ratcliff-Obershelp)
- Gestion d'erreur robuste (timeout, r√©seau, parsing JSON)

**M√©thodes principales** :
- `search(term)` : Recherche g√©n√©rique Babelio
- `verify_author(name)` : V√©rification auteur
- `verify_book(title, author)` : V√©rification livre
- `verify_batch(items)` : Traitement par lots

**Configuration** :
- Headers + cookies pour √©viter blocages Babelio
- Timeout : 10 sec total, 5 sec connexion
- Cache limite : 100 entr√©es m√©moire, illimit√© disque
- Log verbeux : Variable `BABELIO_CACHE_LOG=1`

### FuzzySearchService (Backend API)
**Fichier** : `src/back_office_lmelp/app.py:583-674`

**Responsabilit√©s** :
- Extraction texte des √©pisodes MongoDB
- Recherche fuzzy avec `rapidfuzz` (Python)
- D√©tection segments entre guillemets (titres probables)
- Calcul scores de similarit√© (0-100)

**Endpoint** : `POST /api/fuzzy-search-episode`

**Param√®tres** :
```json
{
  "episode_id": "68bd9ed3582cf994fb66f1d6",  // pragma: allowlist secret
  "query_title": "Fleurs intestinales",
  "query_author": "Vamille"
}
```

**R√©ponse** :
```json
{
  "found_suggestions": true,
  "title_matches": [["üìñ Fleurs intestinales", 100]],
  "author_matches": [["Vamille", 98]],
  "debug_candidates": ["...", "..."],
  "debug_quoted_matches": ["...", "..."]
}
```

**Algorithme** :
1. Extraire texte : `episode.titre + episode.description`
2. Segments entre guillemets ‚Üí titres prioritaires (marqueur üìñ)
3. **N-grams contigus** ‚Üí d√©tection titres multi-mots :
   - Quadrigrams (4 mots) filtr√©s si longueur > 10 caract√®res
   - Trigrams (3 mots) filtr√©s si longueur > 8 caract√®res
   - Bigrams (2 mots) filtr√©s si longueur > 6 caract√®res
4. Mots > 3 caract√®res ‚Üí candidats g√©n√©raux (fallback)
5. `rapidfuzz.process.extract()` pour scoring
6. Filtrage par seuils : `titleScore >= 60`, `authorScore >= 75`

**Priorit√© des candidats** : guillemets > 4-grams > 3-grams > 2-grams > mots isol√©s

---

## Services Frontend Impliqu√©s

### BiblioValidationService (JavaScript)
**Fichier** : `frontend/src/services/BiblioValidationService.js`

**Responsabilit√©s** :
- Orchestration des 4 phases de validation
- Arbitrage intelligent entre sources
- Filtrage suggestions invalides (URLs, fragments)
- Reconstruction noms d'auteurs fragment√©s
- Calcul scores combin√©s (similarit√© + fuzzy)

**M√©thode principale** :
```javascript
async validateBiblio(author, title, publisher, episodeId)
```

**D√©pendances inject√©es** :
- `fuzzySearchService` : Frontend wrapper pour `/api/fuzzy-search-episode`
- `babelioService` : Frontend wrapper pour `/api/verify-babelio`
- `localAuthorService` : Non impl√©ment√© (futur)

**M√©thodes cl√©s** :
- `_tryPhase0DirectValidation()` : Phase 0 (livres extraits)
- `_arbitrateResults()` : Phase 4 (d√©cision finale)
- `_hasGoodGroundTruthMatches()` : D√©tection good matches
- `_hasDecentGroundTruthMatches()` : D√©tection decent matches
- `_extractGroundTruthSuggestion()` : Reconstruction auteur/titre
- `_isValidTitleSuggestion()` : Filtrage URLs/fragments
- `_validateGroundTruthSuggestion()` : Validation ground truth avec Babelio
- `_validateBabelioSuggestion()` : Validation Babelio seule

### BiblioValidationCell (Vue Component)
**Fichier** : `frontend/src/components/BiblioValidationCell.vue`

**Responsabilit√©s** :
- Affichage visuel du statut de validation
- Indicateurs : ‚úÖ Valid√©, üîÑ Suggestion, ‚ùì Non trouv√©, ‚ö†Ô∏è Erreur
- Gestion retry sur erreurs
- Tooltip avec d√©tails

**Props** :
```javascript
{
  author: String,
  title: String,
  publisher: String,
  episodeId: String
}
```

**√âtats** :
- `loading` : Validation en cours
- `result` : R√©sultat de `validateBiblio()`
- `error` : Erreur affich√©e

---

## Configuration et Variables d'Environnement

### Backend (BabelioService)
- `BABELIO_CACHE_LOG` : Verbosit√© des logs cache (`0`/`1`/`true`)
  - `0` (d√©faut) : Logs DEBUG uniquement
  - `1` : Logs INFO pour hit/miss/write

### Rate Limiting
- D√©lai minimum entre requ√™tes Babelio : `0.8 sec`
- Timeout requ√™te Babelio : `10 sec` (total), `5 sec` (connexion)
- Timeout fuzzy search : `30 sec` (configurable dans `api.js`)

### Seuils de Confiance

#### Ground Truth
- **Good matches** : `titleScore >= 80 && authorScore >= 80`
- **Decent matches** : `titleScore >= 75 && authorScore >= 75`
- **Perfect author boost** : Si `authorScore >= 85`, `titleScore >= 35` accept√©

#### Babelio
- **Verified** : `confidence_score >= 0.95`
- **Corrected** : `confidence_score < 0.95`
- **Rejet suggestion fantaisiste** : `confidence_score < 0.8` (sauf livre valid√© + auteur connu)

#### Validation Titre (Filtrage)
- **Longueur minimale** : `>= 3 caract√®res`
- **Mot isol√©** : `>= 8 caract√®res` ou `>= 2 mots`

---

## Tests et Validation

### Tests Backend
- **BabelioService** : Tests unitaires avec mocks API (`tests/test_babelio_service.py`)
- **Fuzzy Search** : Tests int√©gration endpoint (`tests/test_app.py`)
- **Cache** : Tests cache disque/m√©moire (`tests/test_babelio_cache_service.py`)

### Tests Frontend
- **Niveau 1 - UI** : `tests/integration/LivresAuteurs.test.js` (affichage colonne)
- **Niveau 2 - Composant** : `tests/unit/BiblioValidationCell.test.js` (indicateurs visuels)
- **Niveau 3 - Service** : `tests/unit/BiblioValidationService.modular.test.js` (logique arbitrage)
- **Niveau 4 - Backend** : Tests backend s√©par√©s

### Simulation Phase 0 en Tests
**Note importante** : La Phase 0 (`_getExtractedBooks`) utilise actuellement des **fixtures hardcod√©es** pour les tests uniquement :

```javascript
// BiblioValidationService.js:130-138 (CODE DE TEST)
_getExtractedBooks(episodeId) {
  // Simulation bas√©e sur les fixtures pour Alice Ferney
  if (episodeId === '68ab04b92dc760119d18f8ef') {  // pragma: allowlist secret
    return [
      { author: 'Alice Ferney', title: 'Comme en amour' }
    ];
  }
  return [];
}
```

**En production**, cette m√©thode devrait interroger la collection MongoDB `avis_critique` pour r√©cup√©rer les livres r√©ellement extraits de l'√©pisode (champ `summary`).

### Fixtures de Test
**Fichier** : `frontend/tests/fixtures/biblio-validation-cases.yml`

**Structure** :
```yaml
- input:
    author: "Alain Mabancou"
    title: "Rams√®s de Paris"
    publisher: "Seuil"
    episodeId: "68c707ad6e51b9428ab87e9e"  # pragma: allowlist secret
  output:
    status: "suggestion"
    suggested_author: "Alain Mabanckou"
    suggested_title: "Rams√®s de Paris"
    corrections:
      author: true
      title: false
  expected:  # (Optionnel) Pour cas n√©cessitant intervention manuelle
    status: "suggestion"
    suggested_author: "..."
  review:
    manual_review_required: true
    reason: "..."
```

**Cas couverts** :
- ‚úÖ Validated : 2 cas (Alice Ferney, Am√©lie Nothomb)
- üîÑ Suggestion : 5 cas (Mabancou, Dussain, Mauvignier, Pondi, Carr√®re)
- ‚ùì Not Found : 4 cas (Lefloc, Antico, Bigot, Michaud)

---

## Limitations Connues et Am√©liorations Futures

### Limitations Actuelles

1. **Fuzzy Search avec N-grams**
   - D√©tecte maintenant les titres multi-mots gr√¢ce aux n-grams contigus (ex: "L'invention de Tristan")
   - Limitations restantes :
     - Ne d√©tecte pas les inversions de nom (Le Floch ‚Üí Lefloc)
     - √âchoue sur pr√©noms raccourcis (Nine ‚Üí Nin)
     - Retourne parfois URLs et fragments parasites (filtr√©s en Phase 4)

2. **Pas de Mapping Canonique**
   - Corrections connues non r√©utilis√©es (recalcul √† chaque fois)
   - Pas de base de donn√©es d'auteurs normalis√©s

3. **Phase 0 Enrichie** ‚úÖ
   - Appelle l'API r√©elle `livresAuteursService.getLivresAuteurs()`
   - Double appel de confirmation pour confidence 0.85-0.99
   - Correction automatique d'auteur si livre not_found
   - Taux de succ√®s typique : ~45% des livres trait√©s automatiquement

4. **Babelio Rate Limiting**
   - 0.8 sec entre requ√™tes = lent pour gros volumes
   - Besoin de batch processing optimis√©

### Am√©liorations Propos√©es

#### 1. Mapping Canonique Auteurs
**Fichier** : `data/author-canonical-mapping.yml`

**Structure** :
```yaml
- original: "Gr√©gory Lefloc"
  canonical: "Gr√©gory Le Floch"
  confidence: 1.0
  source: "manual"
  validated_at: "2025-09-07"
```

**Avantages** :
- √âvite de recalculer les cas difficiles
- Base de connaissances r√©utilisable
- Intervention humaine document√©e

#### 2. Recherche par Auteur Babelio First
**Workflow alternatif** :
1. Chercher l'auteur sur Babelio
2. R√©cup√©rer sa bibliographie compl√®te
3. Fuzzy match le titre dans sa bibliographie
4. √âvite les faux positifs (homonymes)

**Cas b√©n√©ficiaires** : Christophe Bigot, Agn√®s Michaux

#### 3. Am√©lioration Fuzzy Search Backend
**Techniques d√©j√† impl√©ment√©es** :
- ‚úÖ N-grams contigus pour titres multi-mots (bigrams, trigrams, quadrigrams)

**Techniques propos√©es** :
- D√©tection phon√©tique (Soundex, Metaphone pour fran√ßais)
- NER (Named Entity Recognition) pour extraction auteurs/titres
- Fine-tuning seuils adaptatifs par type d'erreur

#### 4. Service Local Auteurs
**Base MongoDB** : Collection `auteurs_canoniques`

**Workflow** :
1. V√©rifier cache local d'abord
2. Fallback Babelio si absent
3. Mise √† jour cache apr√®s validation manuelle

**Avantages** :
- Z√©ro latence r√©seau pour auteurs connus
- Contr√¥le complet sur mapping
- Ind√©pendance vis-√†-vis Babelio

---

## Fermeture de la Boucle : Mise √† Jour du Summary Original

### Contexte et Probl√©matique

Le workflow de validation bibliographique corrige les erreurs de transcription Whisper pr√©sentes dans `avis_critique.summary`, mais ces corrections restaient isol√©es dans les collections `livres` et `auteurs`. L'application principale lmelp continuait d'afficher les donn√©es erron√©es du summary original.

**Issue #67** impl√©mente la fermeture de cette boucle de correction.

### Workflow de Mise √† Jour

Lorsqu'un livre/auteur est valid√© via le workflow `/livres-auteurs` :

1. **Sauvegarde du summary original** :
   - Si `summary_origin` n'existe pas encore, copier `summary` ‚Üí `summary_origin`
   - Cela pr√©serve la transcription Whisper brute en cas de besoin de rollback

2. **Mise √† jour du summary avec donn√©es corrig√©es** :
   - Remplacer les donn√©es erron√©es dans `summary` par les donn√©es valid√©es
   - Utiliser les donn√©es des collections `livres` et `auteurs` (sources de v√©rit√©)

3. **Propagation automatique** :
   - L'application lmelp lit `avis_critique.summary` ‚Üí affiche les donn√©es corrig√©es
   - Aucune modification n√©cessaire dans l'application consommatrice

### Exemple de Transformation

**Avant validation (Issue #67)** :
```json
{
  "_id": "avis123",
  "episode_oid": "episode456",
  "summary": "| Alain Mabancou | Rams√®s de Paris | Seuil |\n| Adrien Bosque | L'invention de Tristan | Verdier |"
}
```

**Apr√®s validation de "Alain Mabancou ‚Üí Alain Mabanckou"** :
```json
{
  "_id": "avis123",
  "episode_oid": "episode456",
  "summary": "| Alain Mabanckou | Rams√®s de Paris | Seuil |\n| Adrien Bosque | L'invention de Tristan | Verdier |",
  "summary_origin": "| Alain Mabancou | Rams√®s de Paris | Seuil |\n| Adrien Bosque | L'invention de Tristan | Verdier |"
}
```

**Apr√®s validation de "Adrien Bosque ‚Üí Adrien Bosc"** :
```json
{
  "_id": "avis123",
  "episode_oid": "episode456",
  "summary": "| Alain Mabanckou | Rams√®s de Paris | Seuil |\n| Adrien Bosc | L'invention de Tristan | Verdier |",
  "summary_origin": "| Alain Mabancou | Rams√®s de Paris | Seuil |\n| Adrien Bosque | L'invention de Tristan | Verdier |"
}
```

### S√©curit√© et Rollback

- **`summary_origin`** : Pr√©serve toujours la transcription Whisper originale
- **Idempotence** : `summary_origin` n'est √©crit qu'une seule fois (√† la premi√®re correction)
- **Rollback possible** : En cas d'erreur, on peut restaurer `summary_origin` ‚Üí `summary`

### Impact sur le Syst√®me

**B√©n√©fices** :
- ‚úÖ Les utilisateurs de l'application lmelp voient les donn√©es corrig√©es
- ‚úÖ R√©duction de la dette technique (donn√©es coh√©rentes entre apps)
- ‚úÖ Backup automatique de la transcription originale

**Collections affect√©es** :
- `avis_critiques` : Ajout du champ `summary_origin`, modification de `summary`

**Services impliqu√©s** :
- Backend : Endpoint `/api/livres-auteurs/validate-suggestion` (mise √† jour summary)
- MongoDB : Service de mise √† jour `avis_critiques`

---

## Debugging et Monitoring

### Logs de Debug

#### Backend (BabelioService)
**Activation** : `BABELIO_CACHE_LOG=1 python -m back_office_lmelp.app`

**Exemple** :
```
[BabelioCache] MISS keys=(orig='Alain Mabancou', norm='alain mabancou')
[BabelioCache] WROTE keys=(orig='Alain Mabancou', norm='alain mabancou') items=3
[BabelioCache] HIT (orig) key='Alain Mabancou' items=3 ts=1640995200.0
```

#### Frontend (Console)
**Tests** : `npm test -- BiblioValidation --reporter verbose`

**Browser** : Console DevTools affiche les appels API

### Fixture Capture (Tests)
**Service** : `FixtureCaptureService.js`

**Activation** :
```javascript
import { fixtureCaptureService } from './FixtureCaptureService.js';

fixtureCaptureService.startCapture();
await validateBiblio(...);
const fixtures = fixtureCaptureService.stopCapture();
console.log(JSON.stringify(fixtures, null, 2));
```

**Utile pour** :
- Capturer r√©ponses API r√©elles
- G√©n√©rer fixtures de test automatiquement
- Reproduire bugs en environnement contr√¥l√©

---

## R√©f√©rences

### Documentation
- [Validation Biblio Tests](validation-biblio-tests.md) : Architecture tests hi√©rarchiques
- Fixtures YAML : `frontend/tests/fixtures/biblio-validation-cases.yml` (cas de test r√©els)

### Code Source Principal
- **Backend** :
  - `src/back_office_lmelp/services/babelio_service.py` : Service Babelio
  - `src/back_office_lmelp/app.py:583-674` : Endpoint fuzzy search
- **Frontend** :
  - `frontend/src/services/BiblioValidationService.js` : Orchestration
  - `frontend/src/components/BiblioValidationCell.vue` : Composant affichage

### Historique GitHub
Pour l'historique d√©taill√© des d√©veloppements, consulter les issues suivantes :
- Phase 0 - Double appel et correction auteur : Issue #75
- Filtrage URLs/fragments : Issue #74
- Phase 0 livres extraits (base) : Issue #68
- Fermeture de la boucle - Mise √† jour summary : Issue #67
- Collections management : Issue #66

---

## Glossaire

- **Ground Truth** : Donn√©es de r√©f√©rence extraites des transcriptions d'√©pisodes (titre + description)
- **Fuzzy Search** : Recherche approximative tol√©rant les fautes d'orthographe (algorithme Levenshtein/rapidfuzz)
- **Babelio** : Site web de r√©f√©rence bibliographique fran√ßais (source de v√©rit√© externe)
- **Confidence Score** : Score de confiance 0.0-1.0 mesurant la similarit√© entre donn√©es originales et suggestions
- **Rate Limiting** : Limitation du nombre de requ√™tes par seconde pour respecter les serveurs externes
- **Arbitrage** : Processus de d√©cision combinant plusieurs sources de donn√©es pour choisir la meilleure suggestion
- **Phase 0** : Validation directe des livres extraits (nouveau workflow Issue #68)
- **Not Found** : Statut indiquant qu'aucune suggestion fiable n'a pu √™tre trouv√©e (n√©cessite intervention manuelle)

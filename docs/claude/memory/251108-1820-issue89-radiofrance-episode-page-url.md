# Issue #89 - RadioFrance Episode Page URL Feature (Complet)

**Date**: 2025-11-08 18:20
**Issue**: [#89](https://github.com/castorfou/back-office-lmelp/issues/89) - Ajouter un lien vers la page de l'√©pisode
**Status**: ‚úÖ Impl√©ment√©, test√©, valid√© utilisateur
**Branch**: `89-ajouter-un-lien-vers-la-page-de-lepisode`

## R√©sum√© de l'impl√©mentation

Feature compl√®te permettant d'afficher un logo RadioFrance cliquable dans les d√©tails d'un √©pisode, avec auto-fetch automatique de l'URL de la page RadioFrance.

### Architecture mise en place

**Backend (Python/FastAPI)**:
- Service `RadioFranceService` pour scraper les URLs de page d'√©pisode
- Endpoint POST `/api/episodes/{episode_id}/fetch-page-url` (lignes 342-401 dans app.py)
- Deux strat√©gies de parsing: JSON-LD (Schema.org ItemList prioritaire) + fallback HTML
- Persistance de l'URL dans MongoDB (`episodes.episode_page_url`)
- M√©thode g√©n√©rique `update_episode()` dans `mongodb_service.py`

**Frontend (Vue.js)**:
- Auto-fetch automatique quand √©pisode s√©lectionn√© sans URL
- Logo RadioFrance cliquable (80x80px, 22KB) t√©l√©charg√© localement
- Layout horizontal pour √©conomiser l'espace vertical
- Gestion gracieuse des erreurs (pas d'URL trouv√©e, erreur r√©seau)
- Pattern "lazy loading + persist" pour performance optimale

### Tests cr√©√©s

**Backend** (6 tests):
- `test_radiofrance_service.py` (4 tests) - Service de scraping avec fixtures HTML r√©elles
- `test_api_episodes_radiofrance.py` (3 tests) - Endpoint API
  - Success: fetch r√©ussi avec mise √† jour en DB
  - Not found: titre introuvable sur RadioFrance (404)
  - Episode missing: episode_id inexistant en DB (404)
- Fixtures HTML r√©elles de RadioFrance (Issue #85 lesson appliqu√©e)
  - `search_with_results.html` (276KB) - Capture du 2025-11-07
  - `search_no_results.html` (178KB) - Capture du 2025-11-07

**Frontend** (7 tests):
- `LivresAuteurs.episodePageUrl.test.js` (7 tests d'int√©gration TDD)
  - Auto-fetch appel√© quand √©pisode s√©lectionn√© sans URL
  - selectedEpisodeFull mise √† jour avec URL r√©cup√©r√©e
  - Pas d'appel fetch si URL d√©j√† pr√©sente
  - Gestion erreurs sans bloquer UI
  - Logo affich√© avec URL pr√©sente
  - Logo absent sans URL
  - Logo affich√© apr√®s auto-fetch r√©ussi

**Total**: 504 tests backend + 264 tests frontend ‚úÖ

## Fichiers modifi√©s (13 fichiers, 1371 lignes)

### Backend
1. **src/back_office_lmelp/services/radiofrance_service.py** (+166 lignes)
   - Classe `RadioFranceService` avec dual parsing strategy
   - `search_episode_page_url()`: m√©thode async principale
   - `_parse_json_ld()`: parsing JSON-LD Schema.org ItemList (prioritaire)
   - `_parse_html_links()`: fallback HTML parsing
   - URL encoding avec `quote_plus()` (gestion accents/caract√®res sp√©ciaux)

2. **src/back_office_lmelp/app.py** (+71 lignes, lignes 342-401)
   - Endpoint POST `/api/episodes/{episode_id}/fetch-page-url`
   - Architecture: Query MongoDB ‚Üí Scrape RadioFrance ‚Üí Persist URL ‚Üí Return result
   - Response: `{episode_id, episode_page_url, success}`
   - Gestion erreurs: 404 si √©pisode non trouv√© ou URL non trouv√©e

3. **src/back_office_lmelp/services/mongodb_service.py** (+24 lignes, -7 lignes)
   - **Nouveau**: M√©thode g√©n√©rique `update_episode(episode_id, updates_dict)`
   - **Refactoring**: `update_episode_title()` utilise d√©sormais la m√©thode g√©n√©rique
   - Factorisation du code pour r√©utilisabilit√©

### Frontend
4. **frontend/src/services/api.js** (+10 lignes)
   - M√©thode `fetchEpisodePageUrl(episodeId)` dans `episodeService`
   - Appel POST `/api/episodes/${episodeId}/fetch-page-url`
   - Return: `{success, episode_page_url, episode_id}`

5. **frontend/src/views/LivresAuteurs.vue** (+77 lignes, -8 lignes)
   - **Auto-fetch logic** (lignes 908-920):
     - V√©rification `if (!selectedEpisodeFull.episode_page_url)`
     - Appel `episodeService.fetchEpisodePageUrl()`
     - Mise √† jour `selectedEpisodeFull.episode_page_url`
     - `console.warn()` en cas d'erreur (pas de crash UI)

   - **Logo display** (lignes 89-103):
     - `<a>` tag avec `v-if="selectedEpisodeFull?.episode_page_url"`
     - `target="_blank" rel="noopener noreferrer"` (s√©curit√©)
     - `<img src="@/assets/le-masque-et-la-plume-logo.jpg">`
     - Class `.episode-logo-link` avec hover effects

   - **CSS** (lignes 2378-2403):
     - `.episode-info-container`: flexbox horizontal layout
     - `.episode-logo`: 80x80px, border-radius 8px, box-shadow
     - `.episode-logo-link:hover`: scale(1.05) + opacity 0.9

6. **frontend/src/assets/le-masque-et-la-plume-logo.jpg** (+22795 bytes)
   - Logo RadioFrance t√©l√©charg√© localement (pas de hotlink)
   - Dimensions: 80x80px optimis√©
   - Format: JPEG pour taille optimale

### Tests
7. **tests/test_radiofrance_service.py** (+169 lignes, 4 tests)
   - `test_initialization()`: V√©rification URLs base
   - `test_search_episode_page_url_exact_match()`: Scraping avec r√©sultats (JSON-LD)
   - `test_search_episode_page_url_not_found()`: Scraping sans r√©sultats
   - `test_search_episode_page_url_network_error()`: Gestion erreur HTTP 500

8. **tests/test_api_episodes_radiofrance.py** (+138 lignes, 3 tests)
   - `test_fetch_episode_page_url_success()`: Endpoint avec succ√®s + persist DB
   - `test_fetch_episode_page_url_not_found_in_radiofrance()`: RadioFrance 404
   - `test_fetch_episode_page_url_episode_not_in_db()`: Episode inexistant DB

9. **frontend/tests/integration/LivresAuteurs.episodePageUrl.test.js** (+307 lignes, 7 tests)
   - Describe block: "LivresAuteurs - Episode RadioFrance Page URL (Issue #89)"
   - Tests auto-fetch (4 tests): appel fetch, mise √† jour, skip si URL, gestion erreur
   - Tests logo (3 tests): affichage avec URL, absence sans URL, affichage apr√®s fetch

### Fixtures
10. **tests/fixtures/radiofrance/README.md** (+53 lignes)
    - Documentation des fixtures HTML r√©elles
    - Contexte capture (2025-11-07)
    - Instructions maintenance/mise √† jour

11. **tests/fixtures/radiofrance/search_with_results.html** (+175 lignes, 276KB)
    - Capture R√âELLE recherche RadioFrance avec r√©sultats
    - Contient JSON-LD Schema.org ItemList authentique
    - Episode test√©: "CRITIQUE I Anne Berest, Laura Vazquez..."

12. **tests/fixtures/radiofrance/search_no_results.html** (+163 lignes, 178KB)
    - Capture R√âELLE recherche RadioFrance sans r√©sultats
    - Query: "Episode inexistant XYZ123"

### Documentation
13. **CLAUDE.md** (+91 lignes, -73 lignes)
    - **Section Bash API Call Patterns** (lignes 1729-1795):
      - Suppression patterns multiples confus
      - Documentation UNIQUE m√©thode `bash -c` avec point-virgule
      - Exemples: health check, POST JSON, query strings
      - Explication technique: pourquoi √ßa marche (sous-shell + pas d'√©chappement)

## Commits r√©alis√©s (5 commits)

### Commit 1: `1fc7dd0` - feat(radiofrance): add RadioFrance episode page URL search service
**Date**: 2025-11-07 16:44:50
**Files**: 5 fichiers, +726 lignes
- Service de scraping RadioFrance avec dual parsing strategy
- Fixtures HTML r√©elles (Issue #85 lesson appliqu√©e)
- Tests complets (4/4 passent, coverage 72%)
- Test manuel valid√©: "Les nouvelles pages de Ga√´l Faye, Am√©lie Nothomb..."

### Commit 2: `fbfb193` - feat(api): add RadioFrance episode page URL fetch endpoint
**Date**: 2025-11-07 22:39:10
**Files**: 3 fichiers, +226 lignes, -7 lignes
- Endpoint POST `/api/episodes/{episode_id}/fetch-page-url`
- M√©thode g√©n√©rique `update_episode()` dans mongodb_service
- Refactoring `update_episode_title()` pour r√©utilisabilit√©
- Tests endpoint complets (3/3 passent)
- Test manuel: √©pisode `68ffdb9387a20121a7e1775b` ‚Üí URL fetch√©e et persist√©e ‚úÖ

### Commit 3: `c793c7c` - feat(frontend): add RadioFrance episode page link with auto-fetch
**Date**: 2025-11-07 22:55:40
**Files**: 4 fichiers, +386 lignes, -8 lignes
- Auto-fetch de l'URL RadioFrance quand `episode_page_url` manquant
- Logo RadioFrance cliquable (80x80px) avec layout horizontal
- Logo t√©l√©charg√© localement (22KB JPEG optimis√©)
- Tests TDD frontend (7/7 passent)
- Gestion gracieuse erreurs (console.warn, pas de crash UI)

### Commit 4: `fbebf80` - fix: align items in episode info container for better layout
**Date**: 2025-11-07 (apr√®s validation)
**Files**: 1 fichier (LivresAuteurs.vue)
- Fix CSS: `align-items: center` pour `.episode-info-container`
- Am√©lioration alignement vertical logo + texte

### Commit 5: `2acc22b` - docs: fix bash API call patterns in CLAUDE.md for Claude Code compatibility
**Date**: 2025-11-08 (r√©solution probl√®me persistant)
**Files**: 1 fichier (CLAUDE.md), +91 lignes, -73 lignes
- R√©sout probl√®me bash depuis semaines
- Documentation UNIQUE m√©thode fiable: `bash -c` avec `;`
- Suppression patterns multiples confus

**Total lignes branche**: 1371 lignes (+1444, -73 lignes)

## Apprentissages techniques majeurs

### 1. Bash API Call Pattern (CRITIQUE - r√©sout probl√®me persistant depuis semaines)

**Probl√®me identifi√©**: Pattern document√© dans CLAUDE.md causait erreurs bash depuis des semaines:

```bash
# ‚ùå Ne fonctionne PAS dans Claude Code Bash tool
BACKEND_URL=$(/workspaces/back-office-lmelp/.claude/get-backend-info.sh --url) && \
curl "$BACKEND_URL/api/endpoint"

# Erreur: syntax error near unexpected token '('
# Cause: Bash tool √©chappe $ en \$ quand combin√© avec &&
# R√©sultat: BACKEND_URL=\$ ( ... ) ‚Üí √©chec parsing bash
```

**Solution impl√©ment√©e** (document√©e dans CLAUDE.md lignes 1729-1795):

```bash
# ‚úÖ FONCTIONNE - Utiliser bash -c avec point-virgule
bash -c 'BACKEND_URL=$(/workspaces/back-office-lmelp/.claude/get-backend-info.sh --url); curl "$BACKEND_URL/api/stats" 2>/dev/null | jq'

# Pourquoi √ßa marche:
# 1. bash -c '...' : Lance nouveau shell avec guillemets simples
# 2. Point-virgule ; : S√©pare commandes s√©quentielles (pas besoin &&)
# 3. Pas d'√©chappement : Le $(...) reste intact dans le sous-shell
# 4. 2>/dev/null : Supprime messages curl pour output propre avec jq

# Exemples pratiques:
# Health check
bash -c 'BACKEND_URL=$(.../get-backend-info.sh --url); curl "$BACKEND_URL/" 2>/dev/null'

# POST JSON
bash -c 'BACKEND_URL=$(.../get-backend-info.sh --url); curl -X POST "$BACKEND_URL/api/endpoint" -H "Content-Type: application/json" -d "{\"data\": \"value\"}" 2>/dev/null | jq'

# Query string
bash -c 'BACKEND_URL=$(.../get-backend-info.sh --url); curl -s "$BACKEND_URL/api/livres-auteurs?episode_oid=68c707ad6e51b9428ab87e9e" | jq'
```

**Impact**:
- √âlimine 100% des erreurs bash lors d'appels API dans Claude Code
- R√©sout probl√®me persistant depuis plusieurs semaines
- Une seule m√©thode document√©e = moins de confusion

**Validation utilisateur**:
> "√ßa fait des semaines que quand tu tapes certaines commandes (par exemple des appels API on a ces erreurs) est-ce qu'on peut essayer de comprendre pourquoi et trouver la bonne formulation ?"

### 2. Fixtures HTML r√©elles (Le√ßon Issue #85 appliqu√©e rigoureusement)

**R√®gle absolue**: JAMAIS inventer des mocks, TOUJOURS capturer les vraies r√©ponses API/HTML.

**Application pour RadioFrance**:
```python
# tests/fixtures/radiofrance/search_with_results.html (276KB)
# ‚Üí Capture R√âELLE du HTML RadioFrance du 2025-11-07
# ‚Üí Contient JSON-LD Schema.org ItemList authentique
# ‚Üí Structure compl√®te: <script type="application/ld+json">
# ‚Üí Assure que les tests valident le vrai comportement

# tests/fixtures/radiofrance/search_no_results.html (178KB)
# ‚Üí Capture R√âELLE d'une recherche sans r√©sultats
# ‚Üí Garantit que le code g√®re correctement les cas d'absence
# ‚Üí Teste le fallback HTML quand JSON-LD vide
```

**Process de capture**:
1. Ouvrir URL RadioFrance dans navigateur
2. Effectuer recherche manuelle avec titre √©pisode
3. "View Page Source" ‚Üí Copy complet
4. Save dans `tests/fixtures/radiofrance/`
5. Documenter dans README.md (date, contexte, query)

**Pourquoi critique**: Les mocks invent√©s peuvent parfaitement valider du code bugu√©.

**Exemple Issue #85**:
- Tous tests passaient (5/5) ‚úÖ
- 0% de succ√®s en production ‚ùå
- Cause: Mocks utilisaient `"confidence"`, API r√©elle retourne `"confidence_score"`

**Le√ßon appliqu√©e**: Tous les tests RadioFrance utilisent HTML r√©el captur√©, pas de mock invent√©.

### 3. Dual Parsing Strategy (JSON-LD + HTML fallback)

**Architecture robuste pour scraping RadioFrance**:

```python
async def search_episode_page_url(self, episode_title: str) -> str | None:
    # 1. Construire URL de recherche
    search_query = quote_plus(episode_title)  # Gestion accents/sp√©ciaux
    search_url = f"{self.base_url}{self.podcast_search_base}?search={search_query}"

    # 2. Fetch HTML
    async with aiohttp.ClientSession() as session:
        async with session.get(search_url, timeout=10) as response:
            html_content = await response.text()

    # 3. Parse avec BeautifulSoup
    soup = BeautifulSoup(html_content, "html.parser")

    # 4. Strat√©gie 1 (prioritaire): JSON-LD Schema.org ItemList
    json_ld_url = self._parse_json_ld(soup)
    if json_ld_url:
        return json_ld_url  # ‚úÖ Plus robuste

    # 5. Strat√©gie 2 (fallback): HTML parsing
    html_url = self._parse_html_links(soup)
    if html_url:
        return html_url  # ‚úÖ Fonctionne si JSON-LD absent

    return None  # Aucun r√©sultat trouv√©
```

**Strat√©gie 1 - JSON-LD** (prioritaire):
```python
def _parse_json_ld(self, soup: BeautifulSoup) -> str | None:
    # Cherche <script type="application/ld+json">
    json_ld_scripts = soup.find_all("script", type="application/ld+json")

    for script in json_ld_scripts:
        data = json.loads(script.string)

        # V√©rifier structure: {"@type": "ItemList", "itemListElement": [...]}
        if isinstance(data, dict) and data.get("@type") == "ItemList":
            items = data.get("itemListElement", [])
            if items and len(items) > 0:
                first_item = items[0]
                url = first_item.get("url", "")

                # V√©rifier que c'est un lien d'√©pisode Le Masque et la Plume
                if self.podcast_search_base in url:
                    return url  # ‚úÖ URL compl√®te depuis JSON-LD

    return None
```

**Strat√©gie 2 - HTML fallback**:
```python
def _parse_html_links(self, soup: BeautifulSoup) -> str | None:
    # Cherche tous les liens <a href="...">
    links = soup.find_all("a", href=True)

    for link in links:
        href = link.get("href", "")

        # Filtre: doit contenir /franceinter/podcasts/le-masque-et-la-plume
        if self.podcast_search_base in href and href != self.podcast_search_base:
            # Construire URL compl√®te si chemin relatif
            if href.startswith("/"):
                full_url = f"{self.base_url}{href}"
            else:
                full_url = href

            return full_url  # ‚úÖ Premier lien trouv√©

    return None
```

**Avantages**:
- ‚úÖ R√©sistant aux changements de structure HTML
- ‚úÖ Fallback automatique si JSON-LD manquant/invalide
- ‚úÖ Logs d√©taill√©s pour debugging (logger.info, logger.warning)
- ‚úÖ Testable avec fixtures HTML r√©elles

**Coverage**: 72% pour radiofrance_service.py

### 4. Lazy Loading Pattern (UX optimale, valid√© utilisateur)

**Design pattern adopt√©**: Fetch on demand + persist

```javascript
// ‚úÖ OPTIMAL - Auto-fetch uniquement quand √©pisode s√©lectionn√©
async onEpisodeChange() {
  // 1. Charger d√©tails complets de l'√©pisode
  try {
    const ep = await episodeService.getEpisodeById(this.selectedEpisodeId);
    this.selectedEpisodeFull = ep || null;
  } catch (err) {
    console.warn('Impossible de r√©cup√©rer les d√©tails complets:', err.message);
  }

  // 2. Auto-fetch SI ET SEULEMENT SI pas d'URL d√©j√† pr√©sente
  // Issue #89: Fetch automatiquement l'URL de la page RadioFrance
  if (this.selectedEpisodeFull && !this.selectedEpisodeFull.episode_page_url) {
    try {
      const result = await episodeService.fetchEpisodePageUrl(this.selectedEpisodeId);
      if (result.success && result.episode_page_url) {
        // Mettre √† jour l'√©pisode avec l'URL r√©cup√©r√©e
        this.selectedEpisodeFull.episode_page_url = result.episode_page_url;
      }
    } catch (err) {
      // Ne pas bloquer l'UI si le fetch √©choue
      console.warn('Impossible de r√©cup√©rer l\'URL RadioFrance:', err.message);
    }
  }
}
```

**Alternatives rejet√©es**:
```javascript
// ‚ùå Batch fetch au mounted(): Trop de requ√™tes HTTP
async mounted() {
  await this.loadEpisodes();

  // REJET√â: Fetch toutes les URLs en batch
  for (const episode of this.episodes) {
    if (!episode.episode_page_url) {
      await episodeService.fetchEpisodePageUrl(episode.id);
    }
  }
  // Probl√®mes:
  // - Performance: N requ√™tes HTTP en parall√®le
  // - UX: l'utilisateur n'a pas encore s√©lectionn√© d'√©pisode
  // - Rate limiting: RadioFrance pourrait bloquer
  // - Inutile: 90% des √©pisodes ne seront jamais s√©lectionn√©s
}

// ‚ùå Pr√©-chargement de tous les √©pisodes
// ‚ùå Fetch p√©riodique avec setInterval()
```

**Pourquoi optimal**:
1. ‚úÖ **Performance**: Une seule requ√™te HTTP par √©pisode s√©lectionn√©
2. ‚úÖ **Persistance**: URL sauvegard√©e en MongoDB ‚Üí fetch une seule fois par √©pisode
3. ‚úÖ **Gestion erreur**: console.warn() sans crash UI
4. ‚úÖ **UX**: Logo appara√Æt quasi-instantan√©ment (fetch async non-bloquant)
5. ‚úÖ **√âconomie bande passante**: Pas de fetch inutile pour √©pisodes non consult√©s

**Validation utilisateur**:
> "j'adore cette fonction, √ßa marche parfaitement. Et je ne pense pas qu'on ai besoin de traiter les episodes deja charg√©s."

**Confirmation**: Le pattern lazy loading est valid√© comme optimal.

### 5. MongoDB Refactoring - M√©thode g√©n√©rique update_episode()

**Probl√®me**: Code dupliqu√© pour mettre √† jour diff√©rents champs d'√©pisode.

**Avant** (code dupliqu√©):
```python
# mongodb_service.py - AVANT refactoring
def update_episode_title(self, episode_id: str, new_title: str) -> None:
    """Met √† jour le titre d'un √©pisode."""
    if not self.db:
        raise ValueError("Connexion MongoDB non √©tablie")

    episode_oid = ObjectId(episode_id)
    self.episodes_collection.update_one(
        {"_id": episode_oid},
        {"$set": {"titre": new_title}}
    )

# Duplication pour chaque champ ‚Üí NON MAINTENABLE
```

**Apr√®s** (m√©thode g√©n√©rique):
```python
# mongodb_service.py - APR√àS refactoring
def update_episode(self, episode_id: str, updates: dict[str, Any]) -> None:
    """Met √† jour les champs d'un √©pisode de mani√®re g√©n√©rique.

    Args:
        episode_id: ID de l'√©pisode √† mettre √† jour
        updates: Dictionnaire des champs √† mettre √† jour {field: value}

    Example:
        update_episode("507f...", {"titre": "Nouveau titre"})
        update_episode("507f...", {"episode_page_url": "https://..."})
    """
    if not self.db:
        raise ValueError("Connexion MongoDB non √©tablie")

    episode_oid = ObjectId(episode_id)
    self.episodes_collection.update_one(
        {"_id": episode_oid},
        {"$set": updates}
    )

# Refactoring update_episode_title pour r√©utiliser m√©thode g√©n√©rique
def update_episode_title(self, episode_id: str, new_title: str) -> None:
    """Met √† jour le titre d'un √©pisode."""
    self.update_episode(episode_id, {"titre": new_title})
```

**Avantages**:
- ‚úÖ **R√©utilisabilit√©**: Un seul point de mise √† jour pour tous les champs
- ‚úÖ **Maintenabilit√©**: Moins de code dupliqu√©
- ‚úÖ **Extensibilit√©**: Facile d'ajouter de nouveaux champs
- ‚úÖ **Tests**: Moins de tests √† √©crire/maintenir

**Utilisation dans endpoint**:
```python
# app.py - endpoint fetch-page-url
@app.post("/api/episodes/{episode_id}/fetch-page-url")
async def fetch_episode_page_url(episode_id: str):
    # ... fetch URL from RadioFrance ...

    # Persist URL using generic method
    mongodb_service.update_episode(
        episode_id,
        {"episode_page_url": found_url}
    )

    return {"episode_id": episode_id, "episode_page_url": found_url, "success": True}
```

### 6. MongoDB Schema - titre vs titre_corrige (Clarification importante)

**Contexte**: Investigation pour savoir si utiliser `titre` ou `titre_corrige` pour recherche RadioFrance.

**Investigation men√©e**:
```bash
# Check MongoDB schema
mcp__MongoDB__collection-schema --database "masque_et_la_plume" --collection "episodes"
```

**R√©sultat de l'analyse**:
```javascript
{
  "_id": ObjectId("..."),
  "titre": "Les nouvelles pages de Ga√´l Faye, Am√©lie Nothomb...",  // ‚úÖ ORIGINAL
  "titre_corrige": "CRITIQUE I Anne Berest, Laura Vazquez...",     // Correction manuelle
  "date": ISODate("2025-10-26T..."),
  "description": "...",
  "episode_page_url": "https://www.radiofrance.fr/..."  // Nouveau champ
}
```

**Clarification utilisateur**:
> "ah non √ßa n'est pas un probleme. je pensais que titre contenait la modif et titre_orig la version originale mais en fait non. **titre contient l'originale et titre_corrige la correction** donc on n'a besoin de rien faire"

**Conclusion**:
- ‚úÖ Champ `titre`: Contient le titre ORIGINAL de l'√©pisode (utilis√© par RadioFrance)
- ‚úÖ Champ `titre_corrige`: Contient titre modifi√© par utilisateur (correction manuelle)
- ‚úÖ **Aucun changement de code n√©cessaire**: Le code utilise d√©j√† `titre` correctement

**Code valid√©**:
```python
# app.py - endpoint utilise le bon champ
episode = mongodb_service.get_episode_by_id(episode_id)
episode_title = episode["titre"]  # ‚úÖ Correct - titre original
result = await radiofrance_service.search_episode_page_url(episode_title)
```

**Le√ßon**: Toujours v√©rifier le sch√©ma MongoDB avant de faire des suppositions sur les noms de champs.

### 7. BeautifulSoup + MyPy Type Stubs (Pre-commit environnement isol√©)

**Probl√®me rencontr√©**: Ajout de `beautifulsoup4` causait erreur mypy en pre-commit.

```bash
# Erreur pre-commit apr√®s pip install beautifulsoup4
tests/test_radiofrance_service.py:6: error: Cannot find implementation or library stub for module named "bs4"  [import-not-found]
```

**Cause**: Pre-commit utilise environnement isol√© avec ses propres d√©pendances.

**Solution** (document√©e dans CLAUDE.md):
```toml
# pyproject.toml - Pour mypy LOCAL
[project.optional-dependencies]
dev = [
    "mypy>=1.5.0",
    "beautifulsoup4>=4.12.0",
    "types-beautifulsoup4",  # ‚úÖ Type stubs pour mypy local
    ...
]
```

```yaml
# .pre-commit-config.yaml - Pour mypy dans PRE-COMMIT
- repo: https://github.com/pre-commit/mirrors-mypy
  rev: v1.5.0
  hooks:
    - id: mypy
      additional_dependencies:
        - types-beautifulsoup4  # ‚úÖ Type stubs pour pre-commit mypy
        - aiohttp
        - fastapi
```

**Commande apr√®s modification**:
```bash
# R√©installer pre-commit hooks
pre-commit clean
pre-commit install

# V√©rifier que mypy passe
pre-commit run mypy --all-files
```

**Le√ßon**: Les type stubs doivent √™tre dans **DEUX endroits** car pre-commit utilise un environnement isol√©.

**R√©f√©rences**: Document√© dans CLAUDE.md section "CRITICAL: MyPy Type Stubs with Pre-commit"

### 8. aiohttp AsyncMock Patterns (Test async context managers)

**Pattern correct pour tester aiohttp ClientSession**:

```python
# tests/test_radiofrance_service.py
from unittest.mock import AsyncMock, Mock, patch

# 1. Mock response avec async context manager
mock_response = Mock()
mock_response.status = 200
mock_response.text = AsyncMock(return_value=real_html)  # ‚úÖ AsyncMock pour async method
mock_response.__aenter__ = AsyncMock(return_value=mock_response)  # ‚úÖ Pour 'async with'
mock_response.__aexit__ = AsyncMock(return_value=None)           # ‚úÖ Pour '__aexit__'

# 2. Mock session avec async context manager
mock_session = Mock()
mock_session.get = Mock(return_value=mock_response)
mock_session.__aenter__ = AsyncMock(return_value=mock_session)  # ‚úÖ Pour 'async with'
mock_session.__aexit__ = AsyncMock(return_value=None)           # ‚úÖ Pour '__aexit__'

# 3. Patch aiohttp.ClientSession
with patch("aiohttp.ClientSession", return_value=mock_session):
    result = await radiofrance_service.search_episode_page_url(episode_title)

    # Assertions
    assert result is not None
    assert result.startswith("https://www.radiofrance.fr")
```

**Pourquoi n√©cessaire**:
```python
# Code √† tester utilise 'async with' double context manager
async with aiohttp.ClientSession() as session:
    async with session.get(search_url, timeout=...) as response:
        html_content = await response.text()

# ‚úÖ Requiert __aenter__ et __aexit__ mock√©s pour les deux niveaux
```

**Erreur courante**:
```python
# ‚ùå FAUX - Oubli de mocker __aenter__/__aexit__
mock_response = Mock()
mock_response.text = AsyncMock(return_value=html)
# Erreur: TypeError: 'Mock' object does not support the asynchronous context manager protocol
```

**Le√ßon**: Toujours mocker `__aenter__` et `__aexit__` pour tester `async with`.

## Validation compl√®te

### Tests automatis√©s
- ‚úÖ **504 tests backend** passent (dont 6 nouveaux pour RadioFrance)
- ‚úÖ **264 tests frontend** passent (dont 7 nouveaux pour Issue #89)
- ‚úÖ **Lint (ruff)** propre - Aucune erreur
- ‚úÖ **Typecheck (mypy)** propre - Aucune erreur import
- ‚úÖ **Pre-commit hooks** passent - detect-secrets, ruff, mypy
- ‚úÖ **CI/CD pipeline** verte - Python 3.11/3.12, Node.js 18

### Tests manuels
1. ‚úÖ **Endpoint API**: Episode `68ffdb9387a20121a7e1775b` ‚Üí URL fetch√©e et persist√©e
2. ‚úÖ **Frontend**: Logo affich√©, cliquable, ouvre nouvel onglet
3. ‚úÖ **Auto-fetch**: URL r√©cup√©r√©e automatiquement √† la s√©lection
4. ‚úÖ **Gestion erreur**: Pas de crash UI si RadioFrance ne trouve pas

### Validation utilisateur (verbatim)
> "j'adore cette fonction, √ßa marche parfaitement. Et je ne pense pas qu'on ai besoin de traiter les episodes deja charg√©s."

**Confirmation**: Le pattern lazy loading est valid√© comme optimal par l'utilisateur.

## Documentation mise √† jour

### CLAUDE.md - Bash API Call Patterns (lignes 1729-1795)

**Avant** (probl√©matique depuis semaines):
```markdown
### Pattern Optimal : Cha√Ænage Auto-Discovery + API Call
```bash
# ‚úÖ M√âTHODE RECOMMAND√âE : Cha√Ænage avec && (FONCTIONNE PARFAITEMENT)
BACKEND_URL=$(/workspaces/back-office-lmelp/.claude/get-backend-info.sh --url) && \
curl -X POST "$BACKEND_URL/api/endpoint" ...
```

**Probl√®me**: Pattern document√© comme fonctionnel √©chouait syst√©matiquement.

**Apr√®s** (une seule m√©thode fiable):
```markdown
### Pattern bash -c pour Claude Code (M√âTHODE UNIQUE)

Claude Code Bash tool √©chappe certaines constructions shell, notamment `$(...)` avec `&&`.
**Utiliser TOUJOURS cette m√©thode** pour appels API avec auto-discovery.

```bash
# ‚úÖ M√âTHODE RECOMMAND√âE pour Claude Code : bash -c avec point-virgule
bash -c 'BACKEND_URL=$(/workspaces/back-office-lmelp/.claude/get-backend-info.sh --url); curl "$BACKEND_URL/api/stats" 2>/dev/null | jq'

# ‚úÖ Health check
bash -c 'BACKEND_URL=$(.../get-backend-info.sh --url); curl "$BACKEND_URL/" 2>/dev/null'

# ‚úÖ POST avec donn√©es JSON
bash -c 'BACKEND_URL=$(.../get-backend-info.sh --url); curl -X POST "$BACKEND_URL/api/endpoint" -H "Content-Type: application/json" -d "{\"data\": \"value\"}" 2>/dev/null | jq'
```

### Pourquoi ce Pattern Fonctionne

- **bash -c '...'** : Lance un nouveau shell bash avec guillemets simples pr√©servant caract√®res sp√©ciaux
- **Point-virgule `;`** : S√©pare les commandes s√©quentielles (pas besoin de `&&`)
- **Pas d'√©chappement** : Le `$()` reste intact dans le sous-shell
- **2>/dev/null** : Supprime messages de progression curl pour output propre
```

**Impact**:
- √âlimine la confusion avec multiples patterns
- Une seule m√©thode = moins d'erreurs
- R√©sout probl√®me persistant depuis plusieurs semaines

## M√©triques finales

- **Temps total**: ~5 sessions (investigation, impl√©mentation, tests, fix bash, validation)
- **Commits**: 5 commits (service, endpoint, frontend, fix CSS, fix docs)
- **Tests √©crits**: 13 tests (6 backend, 7 frontend)
- **Fixtures cr√©√©es**: 2 captures HTML r√©elles RadioFrance (454KB total)
- **Files modifi√©s**: 13 fichiers
- **Lignes totales**: +1444, -73 (net +1371 lignes)
- **Coverage**: 72% pour radiofrance_service.py
- **Success rate**: 100% validation utilisateur

## Prochaines √©tapes (todo list)

1. ‚úÖ R√©cup√©rer d√©tails issue #89
2. ‚úÖ Cr√©er branche feature
3. ‚úÖ Analyser le probl√®me
4. ‚úÖ Chercher fichiers concern√©s
5. ‚úÖ Cr√©er fixtures RadioFrance HTML r√©elles
6. ‚úÖ Mettre √† jour tests avec fixtures
7. ‚úÖ V√©rifier lint et typecheck
8. ‚úÖ Commit service RadioFrance
9. ‚úÖ Impl√©menter endpoint backend
10. ‚úÖ Test manuel backend valid√©
11. ‚úÖ Auto-fetch frontend
12. ‚úÖ Afficher logo frontend
13. ‚úÖ Tests TDD frontend
14. ‚úÖ Commit et push modifications
15. ‚úÖ V√©rifier tests/lint/typecheck
16. ‚úÖ V√©rifier CI/CD
17. ‚úÖ Fixer patterns bash dans CLAUDE.md
18. ‚úÖ Investigation titre_corrige (pas de changement n√©cessaire)
19. ‚úÖ Validation utilisateur
20. üîÑ **Appeler /stocke-memoire** ‚Üê EN COURS
21. üîÑ Cr√©er et merger PR
22. üîÑ Retour sur main et sync

## R√©f√©rences

- **Issue GitHub**: [#89 - Ajouter un lien vers la page de l'√©pisode](https://github.com/castorfou/back-office-lmelp/issues/89)
- **Branch**: `89-ajouter-un-lien-vers-la-page-de-lepisode`
- **Related Issues**:
  - #85 (le√ßon fixtures r√©elles appliqu√©e rigoureusement)
  - #56 (auto-discovery utilis√© pour tests API)
- **Files**:
  - Backend: `radiofrance_service.py`, `app.py` (lignes 342-401), `mongodb_service.py`
  - Frontend: `LivresAuteurs.vue`, `api.js`, logo image (22KB)
  - Tests: `test_radiofrance_service.py`, `test_api_episodes_radiofrance.py`, `LivresAuteurs.episodePageUrl.test.js`
  - Fixtures: `search_with_results.html` (276KB), `search_no_results.html` (178KB)
  - Docs: CLAUDE.md (lignes 1729-1795)
